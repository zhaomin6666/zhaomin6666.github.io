<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222" media="(prefers-color-scheme: light)"><meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.0.0"><link rel="apple-touch-icon" sizes="180x180" href="https://myblog-1303447677.file.myqcloud.com/BlogFrame/pig_32px_1271682_easyicon.net.ico"><link rel="icon" type="image/png" sizes="32x32" href="https://myblog-1303447677.file.myqcloud.com/BlogFrame/pig_32px_1271682_easyicon.net.ico"><link rel="icon" type="image/png" sizes="16x16" href="https://myblog-1303447677.file.myqcloud.com/BlogFrame/pig_32px_1271682_easyicon.net.ico"><link rel="mask-icon" href="https://myblog-1303447677.file.myqcloud.com/BlogFrame/pig_32px_1271682_easyicon.net.ico" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/black/pace-theme-minimal.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script><script class="next-config" data-name="main" type="application/json">{"hostname":"zm6666.top","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":"utterances","storage":true,"lazyload":false,"nav":null,"activeClass":"utterances"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script><meta name="description" content="目录  Kafka简介和安装以及原生命令行客户端 这块主要是一个Kafka所包含的内部元素的介绍以及简单的使用。 Java客户端以及Spring集成（本篇） Java客户端其实就是原生命令行的一种封装，学习如何使用即可，Spring就是在这个基础上再进行了对象的管理，使用起来并不难。 Kafka集群架构设计 Kafka在设计之初就是为了高吞吐、高性能、高可扩展，所以它的集群架构是"><meta property="og:type" content="article"><meta property="og:title" content="Kafka使用指南2——Java客户端以及Spring集成"><meta property="og:url" content="https://zm6666.top/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6Distribute-framework/How-to-use-Kafka-2-Java_Client/index.html"><meta property="og:site_name" content="Oli的生活杂谈"><meta property="og:description" content="目录  Kafka简介和安装以及原生命令行客户端 这块主要是一个Kafka所包含的内部元素的介绍以及简单的使用。 Java客户端以及Spring集成（本篇） Java客户端其实就是原生命令行的一种封装，学习如何使用即可，Spring就是在这个基础上再进行了对象的管理，使用起来并不难。 Kafka集群架构设计 Kafka在设计之初就是为了高吞吐、高性能、高可扩展，所以它的集群架构是"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2024-04-22T13:10:59.000Z"><meta property="article:modified_time" content="2024-06-02T14:15:34.693Z"><meta property="article:tag" content="Java"><meta property="article:tag" content="Kafka"><meta name="twitter:card" content="summary"><link rel="canonical" href="https://zm6666.top/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6Distribute-framework/How-to-use-Kafka-2-Java_Client/"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://zm6666.top/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6Distribute-framework/How-to-use-Kafka-2-Java_Client/","path":"分布式框架Distribute-framework/How-to-use-Kafka-2-Java_Client/","title":"Kafka使用指南2——Java客户端以及Spring集成"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>Kafka使用指南2——Java客户端以及Spring集成 | Oli的生活杂谈</title><script src="/js/third-party/analytics/baidu-analytics.js"></script><script async src="https://hm.baidu.com/hm.js?a2fa2913e1140bc40e9aef85d103226c"></script><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript></head><body itemscope itemtype="http://schema.org/WebPage" class="use-motion"><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span><span class="toggle-line"></span><span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">Oli的生活杂谈</p><i class="logo-line"></i></a></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%9B%AE%E5%BD%95"><span class="nav-number">1.</span> <span class="nav-text">目录</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9"><span class="nav-number">2.</span> <span class="nav-text">主要内容</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF"><span class="nav-number">3.</span> <span class="nav-text">基础的客户端</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E7%94%9F%E4%BA%A7%E8%80%85"><span class="nav-number">3.1.</span> <span class="nav-text">消息生产者</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%BE%E7%BD%AEproducer%E7%9A%84%E6%A0%B8%E5%BF%83%E5%B1%9E%E6%80%A7"><span class="nav-number">3.1.1.</span> <span class="nav-text">设置Producer的核心属性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9E%84%E5%BB%BA%E6%B6%88%E6%81%AF"><span class="nav-number">3.1.2.</span> <span class="nav-text">构建消息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF"><span class="nav-number">3.1.3.</span> <span class="nav-text">发送消息</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8D%95%E5%90%91%E5%8F%91%E9%80%81"><span class="nav-number">3.1.3.1.</span> <span class="nav-text">单向发送</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%8C%E6%AD%A5%E5%8F%91%E9%80%81"><span class="nav-number">3.1.3.2.</span> <span class="nav-text">同步发送</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BC%82%E6%AD%A5%E5%8F%91%E9%80%81"><span class="nav-number">3.1.3.3.</span> <span class="nav-text">异步发送</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E8%80%85"><span class="nav-number">3.2.</span> <span class="nav-text">消息消费者</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%BE%E7%BD%AEconsumer%E7%9A%84%E6%A0%B8%E5%BF%83%E5%B1%9E%E6%80%A7"><span class="nav-number">3.2.1.</span> <span class="nav-text">设置Consumer的核心属性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8B%89%E5%8F%96%E6%B6%88%E6%81%AF%E5%B9%B6%E5%A4%84%E7%90%86"><span class="nav-number">3.2.2.</span> <span class="nav-text">拉取消息并处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8F%90%E4%BA%A4offset"><span class="nav-number">3.2.3.</span> <span class="nav-text">提交Offset</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%8E%E7%94%9F%E4%BA%A7%E8%80%85%E5%92%8C%E6%B6%88%E8%B4%B9%E8%80%85%E7%9A%84%E5%B1%9E%E6%80%A7%E8%AE%BE%E7%BD%AE%E6%9D%A5%E7%90%86%E8%A7%A3kafka%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="nav-number">4.</span> <span class="nav-text">从生产者和消费者的属性设置来理解Kafka工作机制</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%86%E7%BB%84%E6%9C%BA%E5%88%B6"><span class="nav-number">4.1.</span> <span class="nav-text">消费者分组机制</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#offset%E7%9A%84%E5%AD%98%E5%82%A8"><span class="nav-number">4.1.1.</span> <span class="nav-text">Offset的存储</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#offset%E7%9A%84%E6%9B%B4%E6%96%B0"><span class="nav-number">4.1.2.</span> <span class="nav-text">Offset的更新</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E6%8B%A6%E6%88%AA%E6%9C%BA%E5%88%B6"><span class="nav-number">4.2.</span> <span class="nav-text">生产者拦截机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E5%BA%8F%E5%88%97%E5%8C%96%E6%9C%BA%E5%88%B6"><span class="nav-number">4.3.</span> <span class="nav-text">消息序列化机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E5%88%86%E5%8C%BA%E8%B7%AF%E7%94%B1%E6%9C%BA%E5%88%B6"><span class="nav-number">4.4.</span> <span class="nav-text">消息分区路由机制</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E5%8F%91%E8%B7%AF%E7%94%B1"><span class="nav-number">4.4.1.</span> <span class="nav-text">分发路由</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E7%BB%91%E5%AE%9A"><span class="nav-number">4.4.2.</span> <span class="nav-text">消费绑定</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E6%81%AF%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6"><span class="nav-number">4.5.</span> <span class="nav-text">生产者消息缓存机制</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#accumulator%E7%BC%93%E5%AD%98"><span class="nav-number">4.5.1.</span> <span class="nav-text">accumulator缓存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sender%E5%8F%91%E9%80%81%E5%99%A8"><span class="nav-number">4.5.2.</span> <span class="nav-text">sender发送器</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%91%E9%80%81%E5%BA%94%E7%AD%94%E6%9C%BA%E5%88%B6"><span class="nav-number">4.6.</span> <span class="nav-text">发送应答机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E6%81%AF%E5%B9%82%E7%AD%89%E6%80%A7"><span class="nav-number">4.7.</span> <span class="nav-text">生产者消息幂等性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E6%81%AF%E4%BA%8B%E5%8A%A1"><span class="nav-number">4.8.</span> <span class="nav-text">生产者消息事务</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#springboot%E9%9B%86%E6%88%90kafka"><span class="nav-number">5.</span> <span class="nav-text">SpringBoot集成Kafka</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#pom%E4%B8%AD%E5%BC%95%E7%94%A8kafka"><span class="nav-number">5.1.</span> <span class="nav-text">pom中引用Kafka</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%85%8D%E7%BD%AEspringboot%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">5.2.</span> <span class="nav-text">配置springboot配置文件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BA%94%E7%94%A8%E4%B8%AD%E4%BD%BF%E7%94%A8%E6%A1%86%E6%9E%B6%E6%B3%A8%E5%85%A5%E7%9A%84kafkatemplate%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF"><span class="nav-number">5.3.</span> <span class="nav-text">应用中使用框架注入的KafkaTemplate发送消息</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8kafkalistener%E6%B3%A8%E8%A7%A3%E5%A3%B0%E6%98%8E%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E8%80%85"><span class="nav-number">5.4.</span> <span class="nav-text">使用@KafkaListener注解声明消息消费者</span></a></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="" src="https://myblog-1303447677.file.myqcloud.com/BlogFrame/my-avatar.png"><p class="site-author-name" itemprop="name"></p><div class="site-description" itemprop="description"></div></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">25</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">6</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">19</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author animated"><span class="links-of-author-item"><a href="https://github.com/zhaomin6666" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zhaomin6666" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span><span class="links-of-author-item"><a href="mailto:lanmao_1029@163.com" title="E-Mail → mailto:lanmao_1029@163.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i> E-Mail</a></span></div><div class="cc-license animated" itemprop="license"> <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/big/by_nc_sa.svg" alt="Creative Commons"></a></div></div></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zm6666.top/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6Distribute-framework/How-to-use-Kafka-2-Java_Client/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="https://myblog-1303447677.file.myqcloud.com/BlogFrame/my-avatar.png"><meta itemprop="name" content=""></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Oli的生活杂谈"><meta itemprop="description" content=""></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="Kafka使用指南2——Java客户端以及Spring集成 | Oli的生活杂谈"><meta itemprop="description" content=""></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> Kafka使用指南2——Java客户端以及Spring集成</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2024-04-22 21:10:59" itemprop="dateCreated datePublished" datetime="2024-04-22T21:10:59+08:00">2024-04-22</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2024-06-02 22:15:34" itemprop="dateModified" datetime="2024-06-02T22:15:34+08:00">2024-06-02</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6Distribute-framework/" itemprop="url" rel="index"><span itemprop="name">分布式框架Distribute-framework</span></a></span></span><span id="/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6Distribute-framework/How-to-use-Kafka-2-Java_Client/" class="post-meta-item leancloud_visitors" data-flag-title="Kafka使用指南2——Java客户端以及Spring集成" title="阅读次数"><span class="post-meta-item-icon"><i class="far fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span class="leancloud-visitors-count"></span></span></div></div></header><div class="post-body" itemprop="articleBody"><hr><h1 id="目录">目录</h1><ol type="1"><li><p>Kafka简介和安装以及原生命令行客户端</p><p>这块主要是一个Kafka所包含的内部元素的介绍以及简单的使用。</p></li><li><p>Java客户端以及Spring集成（本篇）</p><p>Java客户端其实就是原生命令行的一种封装，学习如何使用即可，Spring就是在这个基础上再进行了对象的管理，使用起来并不难。</p></li><li><p>Kafka集群架构设计</p><p>Kafka在设计之初就是为了高吞吐、高性能、高可扩展，所以它的集群架构是非常值得学习的。</p></li><li><p>Kafka日志索引详解</p><p>Broker能够高效地处理和保存消息，是Kafka高性能的保障。我们从可见的log文件入手，去研究一下Kafka是如何保证消息高效的流转。</p></li></ol><h1 id="主要内容">主要内容</h1><p>这一部分主要是介绍Kafka在Java客户端上的使用，包括Java客户端和Spring的集成，从客户端的角度去更深入的理解Kafka。同时还会有不同调用参数的介绍，用来实现不同的业务细节。</p><span id="more"></span><hr><h1 id="基础的客户端">基础的客户端</h1><p>要把Kafka在Java中使用起来是非常简单的，只需要引入一个maven依赖即可：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>3.7.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>构建Topic，该Topic有两个分区：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 3 --partitions 2 --topic test-java-client</span></span><br></pre></td></tr></table></figure><h2 id="消息生产者">消息生产者</h2><p>整体来说，构建一个生产者Producer的过程分为三个步骤：</p><ol type="1"><li>设置Producer的核心属性：Producer所有的可选属性都由<code>ProducerConfig</code>类管理。比如<code>ProducerConfig.BOOTSTRAP_SERVERS_CONFIG</code>代表了服务器地址，这边是Kafka服务器的地址。对于大部分重要的属性，在<code>ProducerConfig</code>类中都写了对应<code>参数名+_Doc</code>的注解，介绍还是非常详细的。</li><li>构建消息：作为内容的载体，Kafka的消息结构为Key-Value形式的<code>ProducerRecord</code>类。其中Key会用于在Topic中分配Partition，而Value就是具体的消息内容。</li><li>使用Producer发送消息：发送消息一般有单向发送、同步发送和异步发送三种，对应着不同的安全性和效率。</li></ol><h3 id="设置producer的核心属性">设置Producer的核心属性</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"><span class="comment">// 配置kafka的端口，集群可以节点全配置也可以配置其中的部分节点</span></span><br><span class="line">props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);</span><br><span class="line"><span class="comment">// 配置个性化拦截器类，可以在发送的三个环节（doSend/onAcknowledgement/close）进行自定义的操作</span></span><br><span class="line">props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG,<span class="string">&quot;com.zm.basic.MyInterceptor&quot;</span>);</span><br><span class="line"><span class="comment">// 配置key的序列化类</span></span><br><span class="line">props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,<span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line"><span class="comment">// 配置value的序列化类</span></span><br><span class="line">props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,<span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">Producer&lt;String,String&gt; producer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(props);</span><br></pre></td></tr></table></figure><h3 id="构建消息">构建消息</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">TOPIC</span> <span class="operator">=</span> <span class="string">&quot;test-java-client&quot;</span>;</span><br><span class="line">ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(TOPIC, Integer.toString(i), <span class="string">&quot;MyProducer Send Msg&quot;</span> + i);</span><br></pre></td></tr></table></figure><h3 id="发送消息">发送消息</h3><h4 id="单向发送">单向发送</h4><p>这种发送方式不关心服务端的应答，是速度最快的模式，但是如果消息未发送成功也不会管。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">producer.send(record);</span><br><span class="line">System.out.println(<span class="string">&quot;message &quot;</span> + i + <span class="string">&quot; sent&quot;</span>);</span><br></pre></td></tr></table></figure><h4 id="同步发送">同步发送</h4><p>这种发送方式会阻塞当前线程，等待发送成功之后才会返回<code>RecordMetadata</code>类，可以从返回对象中拿出对应的分区和offset信息。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">RecordMetadata</span> <span class="variable">recordMetadata</span> <span class="operator">=</span> producer.send(record).get();</span><br><span class="line"><span class="type">String</span> <span class="variable">topic</span> <span class="operator">=</span> recordMetadata.topic();</span><br><span class="line"><span class="type">int</span> <span class="variable">partition</span> <span class="operator">=</span> recordMetadata.partition();</span><br><span class="line"><span class="type">long</span> <span class="variable">offset</span> <span class="operator">=</span> recordMetadata.offset();</span><br><span class="line"><span class="type">String</span> <span class="variable">metadata</span> <span class="operator">=</span> recordMetadata.toString();</span><br><span class="line">System.out.println(<span class="string">&quot;metadata:[&quot;</span>+ metadata+<span class="string">&quot;] sent with topic:&quot;</span>+topic+<span class="string">&quot;; partition:&quot;</span>+partition+ <span class="string">&quot;;offset:&quot;</span>+offset);</span><br></pre></td></tr></table></figure><h4 id="异步发送">异步发送</h4><p>这种发送方式发送消息后不阻塞，服务端有应答后会触发回调函数。同样，返回的<code>RecordMetadata</code>类包含对应的分区和offset信息。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 需要定义一个CountDownLatch判断消息是否都发送成功</span></span><br><span class="line"><span class="type">CountDownLatch</span> <span class="variable">latch</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CountDownLatch</span>(<span class="number">5</span>);</span><br><span class="line"><span class="comment">// 构建消息</span></span><br><span class="line"><span class="comment">//...</span></span><br><span class="line"><span class="comment">// 发送消息</span></span><br><span class="line">producer.send(record, <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(e != <span class="literal">null</span>)&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;消息发送失败,&quot;</span>+e.getMessage());</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">topic</span> <span class="operator">=</span> recordMetadata.topic();</span><br><span class="line">            <span class="type">int</span> <span class="variable">partition</span> <span class="operator">=</span> recordMetadata.partition();</span><br><span class="line">            <span class="type">long</span> <span class="variable">offset</span> <span class="operator">=</span> recordMetadata.offset();</span><br><span class="line">            <span class="type">String</span> <span class="variable">metadata</span> <span class="operator">=</span> recordMetadata.toString();</span><br><span class="line">            System.out.println(<span class="string">&quot;metadata:[&quot;</span>+ metadata+<span class="string">&quot;] sent with topic:&quot;</span>+topic+<span class="string">&quot;; partition:&quot;</span>+partition+ <span class="string">&quot;;offset:&quot;</span>+offset);</span><br><span class="line">        &#125;</span><br><span class="line">        latch.countDown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">// 消息处理完才停止发送者。</span></span><br><span class="line">latch.await(); <span class="comment">// 会阻塞直到countDown到0</span></span><br><span class="line">producer.close();</span><br></pre></td></tr></table></figure><p>尝试执行生产者发送5条消息，输出控制台如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">metadata:[test-java-client-0@0] sent with topic:test-java-client; partition:0;offset:0</span><br><span class="line">metadata:[test-java-client-0@1] sent with topic:test-java-client; partition:0;offset:1</span><br><span class="line">metadata:[test-java-client-1@0] sent with topic:test-java-client; partition:1;offset:0</span><br><span class="line">metadata:[test-java-client-1@1] sent with topic:test-java-client; partition:1;offset:1</span><br><span class="line">metadata:[test-java-client-1@2] sent with topic:test-java-client; partition:1;offset:2</span><br></pre></td></tr></table></figure><p>可以看到消息被均匀的发送到了分区0和分区1中。</p><h2 id="消息消费者">消息消费者</h2><p>使用Kafka提供的Consumer类进行快速的消息消费，主要过程也分为三个步骤：</p><ol type="1"><li>设置Consumer的核心属性：Consumer所有的可选属性都由<code>ConsumerConfig</code>类管理。同样比如<code>ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG</code>代表了服务器地址，这边是Kafka服务器的地址。对于大部分重要的属性，在<code>ConsumerConfig</code>类中也都写了对应<code>参数名+_Doc</code>的注解，介绍还是非常详细的。</li><li>拉取消息：Kafka采用消费者主动pull的模式去拉取消息，由消费者去决定自己拉取哪一部分消息。</li><li>处理消息并提交偏移量：消费者拉取到消息之后就可以由业务处理消息了，处理完成之后需要向Broker提交偏移量Offset，这样才能告诉Broker消息消费成功，否则Broker会认为消息消费失败。</li></ol><h3 id="设置consumer的核心属性">设置Consumer的核心属性</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"><span class="comment">// 配置kafka地址，和生产者一样</span></span><br><span class="line">props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);</span><br><span class="line"><span class="comment">// 每个消费者要指定一个group</span></span><br><span class="line">props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test-group-1&quot;</span>);</span><br><span class="line"><span class="comment">// 配置key序列化类</span></span><br><span class="line">props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line"><span class="comment">// 配置value序列化类</span></span><br><span class="line">props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">Consumer&lt;String, String&gt; consumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(props);</span><br><span class="line"><span class="comment">// 1.直接设置订阅的主题</span></span><br><span class="line">consumer.subscribe(Arrays.asList(TOPIC));</span><br><span class="line"><span class="comment">// 2.如需可以自行调整Offset</span></span><br><span class="line"><span class="comment">// 设置分配分区</span></span><br><span class="line"><span class="comment">// List&lt;TopicPartition&gt; topicPartitionList = new ArrayList&lt;&gt;();</span></span><br><span class="line"><span class="comment">// topicPartitionList.add(new TopicPartition(TOPIC,0));</span></span><br><span class="line"><span class="comment">// topicPartitionList.add(new TopicPartition(TOPIC,1));</span></span><br><span class="line"><span class="comment">// consumer.assign(topicPartitionList);</span></span><br><span class="line"><span class="comment">// 自行调整Offset从头开始消费</span></span><br><span class="line"><span class="comment">// consumer.seekToBeginning(topicPartitionList);</span></span><br></pre></td></tr></table></figure><h3 id="拉取消息并处理">拉取消息并处理</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="comment">// 100毫秒超时时间</span></span><br><span class="line">    ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofNanos(<span class="number">100</span>));</span><br><span class="line">    <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;partition = &quot;</span> + record.partition() + <span class="string">&quot;; offset = &quot;</span> + record.offset() + <span class="string">&quot;; key = &quot;</span> + record.key() + <span class="string">&quot;; value= &quot;</span> + record.value());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="提交offset">提交Offset</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//同步提交，表示必须等到offset提交完毕，再去消费下一批数据。</span></span><br><span class="line">consumer.commitSync();</span><br><span class="line"><span class="comment">//异步提交，表示发送完提交offset请求后，就开始消费下一批数据了。不用等到Broker的确认。</span></span><br><span class="line">consumer.commitAsync(); </span><br></pre></td></tr></table></figure><p>尝试使用两个消费者（因为有个两个分区，可以启动两个消费者，数量关系具体在下一个小节说明）消费刚刚生产者发送的5条消息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">consumer1:</span><br><span class="line">partition = 0; offset = 2; key = 0; value= MyProducer0</span><br><span class="line">partition = 0; offset = 3; key = 2; value= MyProducer2</span><br><span class="line"></span><br><span class="line">consumer2:</span><br><span class="line">partition = 1; offset = 3; key = 1; value= MyProducer1</span><br><span class="line">partition = 1; offset = 4; key = 3; value= MyProducer3</span><br><span class="line">partition = 1; offset = 5; key = 4; value= MyProducer4</span><br></pre></td></tr></table></figure><p>可以看到消费者1分配到去消费分区0的消息，而消费者2分配到去消费分区1的消息。如果只启动一个消费者的话，那么该消费者会消费到两个分区所有的消息。</p><h1 id="从生产者和消费者的属性设置来理解kafka工作机制">从生产者和消费者的属性设置来理解Kafka工作机制</h1><h2 id="消费者分组机制">消费者分组机制</h2><p>我们在第一篇文章就提到了每一个消费者都有一个对应的消费组，可能一个消费组下有多个消费者，也可能只有一个消费者。</p><p>在Consumer的属性中，有一个<code>ConsumerConfig.GROUP_ID_CONFIG</code>属性就是用来标识消费组的，在需要使用消费者管理功能或者Kafka提供的Offset管理策略时，<code>ConsumerConfig.GROUP_ID_CONFIG</code>是必填的。还有一个<code>GROUP_INSTANCE_ID_DOC</code>属性可以给消费者一个唯一的标识，一个消费组只会有一个该标识的消费者，这个属性设置可以有效的防止特殊性情况下消费组内不必要的rebalance（比如重启）。</p><p>生产者往一个Topic发送消息时，会尽量均匀地把消息发送的每个Partition中。Partition接收到消息会推送给对应的消费组，每个消费组只会推送一份，也就是一个消费组中只有一个消费组可以接收到消息，而不同的消费组可以都接受到消息。与之相关的还有Offset偏移量，这个偏移量记录了一个消费组在Partition中的消费进度。</p><p>我们将两个消费者的<code>GROUP_INSTANCE_ID_DOC</code>属性分别设置为<code>id1</code>和<code>id2</code>，启动消费者。使用<code>--describe</code>命令查看消费组信息，可以看到<code>test-group-1</code>消费组下两个消费者的消费情况。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group test-group-1</span></span><br><span class="line">GROUP           TOPIC            PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                              HOST            CLIENT-ID</span><br><span class="line">test-group-1    test-java-client 1          3               3               0               id2-c0130d1e-45f2-4020-8903-846919537124 /192.168.56.1   consumer-test-group-1-id2</span><br><span class="line">test-group-1    test-java-client 0          2               2               0               id1-5fd9b499-7329-4aaa-86f8-08f779a404f7 /192.168.56.1   consumer-test-group-1-id1</span><br></pre></td></tr></table></figure><p>其中<code>CURRENT-OFFSET</code>就是当前消费的偏移量，<code>LEO</code>在上一篇文章中提到过，就是总的消息偏移量，<code>LAG</code>是还剩多少消息未消费。</p><p><code>CURRENT-OFFSET</code>需要消费组消费之后主动向Broker提交，提交完成之后Broker会更新这个Partition的消费进度，表示这个消息已经被处理完成。若消费者没有提交Offset，那么Broker会认为这个消息没有处理过，会往对应消费组重新推送，不过会尽量推送给这个消费组中的其他消费者。</p><p>在文章上一节中的示例代码中，我们使用了手动提交Offset的方法，也可以通过设置<code>ENABLE_AUTO_COMMIT_CONFIG</code>为<code>true</code>来开启自动提交。</p><h3 id="offset的存储">Offset的存储</h3><p>Offset是和Partition和Group相关的，所以一个Partition一个Group只能记录一个Offset。由此可以推导出，一个Partition只能有一个消费者进行消费。所以在一个有4个副本的Topic下，一个消费组最多能有4个消费者实例，多的消费者是无法订阅到消息的。</p><p>Offset是在服务端管理的，但是Offset的更新是由客户端发起的。<code>AUTO_OFFSET_RESET_CONFIG</code>参数可以设置服务端在客户端提交的Offset不存在（如数据文件被删除）时的处理方式。设置为<code>earliest</code>将Offset设置为最早的Offset，设置为<code>latest</code>将Offset设置为最新的Offset，设置为<code>none</code>向客户端抛出异常。</p><h3 id="offset的更新">Offset的更新</h3><p>在文章上一节中的示例代码中，我们展示了手动提交Offset的两种方法：同步提交和异步提交。</p><p>同步提交可以保证提交成功Offset之后才确认处理完成，但是会导致消息速度降低。</p><p>异步提交可以提交处理效率，但是如果处理完成之后提交Offset失败，会导致重复消费。</p><p>当然追求效率还可以在接收到消息马上异步提交，同时处理消息，但是如果消息处理失败就会丢失这条消息。</p><p>消费者各种处理Offset的方式各有优缺点，甚至还可以将Offset自行用Redis处理，根据自己的业务处理来更新Offset向前进。</p><h2 id="生产者拦截机制">生产者拦截机制</h2><p>在消息生产者中，<code>INTERCEPTOR_CLASSES_CONFIG</code>属性可以设置自定义拦截器类。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyInterceptor</span> <span class="keyword">implements</span> <span class="title class_">ProducerInterceptor</span>&lt;String, String&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> ProducerRecord&lt;String, String&gt; <span class="title function_">onSend</span><span class="params">(ProducerRecord record)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;发送时拦截：key=&quot;</span> + record.key() + <span class="string">&quot;,partition=&quot;</span> + record.partition() + <span class="string">&quot;,topic=&quot;</span> + record.topic() + <span class="string">&quot;,value=&quot;</span> + record.value());</span><br><span class="line">        <span class="keyword">return</span> record;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onAcknowledgement</span><span class="params">(RecordMetadata metadata, Exception exception)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;发送确认时拦截：partition=&quot;</span> + metadata.partition() + <span class="string">&quot;,topic=&quot;</span> + metadata.topic() + <span class="string">&quot;,offset=&quot;</span> + metadata.offset());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;关闭连接时拦截&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;处理配置项&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在设置了拦截器之后，我们使用异步发送重新调用生产者发送消息。根据控制台打印的顺序，可以清楚地看到拦截器在整个流程中进行拦截的节点：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">处理配置项</span><br><span class="line">发送时拦截：key=0,partition=null,topic=test-java-client,value=MyProducer0</span><br><span class="line">发送时拦截：key=1,partition=null,topic=test-java-client,value=MyProducer1</span><br><span class="line">发送时拦截：key=2,partition=null,topic=test-java-client,value=MyProducer2</span><br><span class="line">发送时拦截：key=3,partition=null,topic=test-java-client,value=MyProducer3</span><br><span class="line">发送时拦截：key=4,partition=null,topic=test-java-client,value=MyProducer4</span><br><span class="line">发送确认时拦截：partition=0,topic=test-java-client,offset=4</span><br><span class="line">metadata:[test-java-client-0@4] sent with topic:test-java-client; partition:0;offset:4</span><br><span class="line">发送确认时拦截：partition=0,topic=test-java-client,offset=5</span><br><span class="line">metadata:[test-java-client-0@5] sent with topic:test-java-client; partition:0;offset:5</span><br><span class="line">发送确认时拦截：partition=1,topic=test-java-client,offset=6</span><br><span class="line">metadata:[test-java-client-1@6] sent with topic:test-java-client; partition:1;offset:6</span><br><span class="line">发送确认时拦截：partition=1,topic=test-java-client,offset=7</span><br><span class="line">metadata:[test-java-client-1@7] sent with topic:test-java-client; partition:1;offset:7</span><br><span class="line">发送确认时拦截：partition=1,topic=test-java-client,offset=8</span><br><span class="line">metadata:[test-java-client-1@8] sent with topic:test-java-client; partition:1;offset:8</span><br><span class="line">关闭连接时拦截</span><br></pre></td></tr></table></figure><p>可以设置多个拦截器，用逗号隔开。</p><p>拦截器可以用来给消息批量赋值，比如给一个对象设置一个发送时间的属性。</p><h2 id="消息序列化机制">消息序列化机制</h2><p>在设置Producer的属性的时候，有两个属性<code>ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG</code>和<code>ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG</code>，分别对应了消息Key的序列化和Value的序列化。</p><p>我们在使用消息队列时，虽然消息是String的可能性非常大，但是还是有很多场景需要传输pojo类型。如果需要把数据进行网络传输到Kafka，那么就需要把这个对象转换成byte[]进行传输，对于常见的类型如String，Double，Long等都实现了默认的序列化类，而业务上自己的对象就需要自行编写序列化类。</p><p>假设拥有一个User对象，姓名：张三，年龄：18，性别：男。我们可以简单粗暴的使用json转换，但是更加效率的方法可以是将数据拼成一个字符串，如<code>value=男018张三</code>。性别只会有男/女，年龄也不会超过999，而姓名放在最后是因为长度不确定，可以从年龄的后一位一直读到最后。经过这样的处理，value值就会尽可能的缩小，提高传输效率和Kafka存储效率。</p><p>其他对于非定长的属性也可以使用数据长度+数据的形式，如<code>value=4:male,2:18,7:zhangsan,8:engineer,</code>表示性别：男，年龄：18，姓名：张三，职业：工程师。</p><p>在生产者设置了序列化方式之后，对应的在消费者也需要反序列化，根据value的特定格式去将byte[]还原成业务对象。</p><p>序列化机制在高并发场景中非常重要的优化机制，除了Kafka，像Netty在进行网络调用时也会定制化序列化机制防止粘包。</p><h2 id="消息分区路由机制">消息分区路由机制</h2><p>在前面的示例中，多分区的Topic的每个分区总是会分到数量均衡的消息，那么消息是如何分区发送的，而消费者又是怎么选择分区去消费的呢？</p><p>我们把问题分为两个：</p><ul><li>Producer根据Key将消息分发到不同的Partition上</li><li>Consumer选择消费特定的Partition的消息</li></ul><h3 id="分发路由">分发路由</h3><p>首先我们来看生产者端。在Producer中我们可以指定一个Partitioner对象来对消息进行分配。使用<code>ProducerConfig.PARTITIONER_CLASS_CONFIG</code>参数来指定个性化的分发实现类。</p><p>Kafka之前提供了三种实现机制，分别是<code>RoundRobinPartitioner</code>，<code>DefaultPartitioner</code>和<code>UniformStickyPartitioner</code>，目前后两个已经被标记为过时，默认使用<code>BuiltInPartitioner</code>（默认实现类没有继承Partitioner接口）。</p><p>默认的<code>BuiltInPartitioner</code>使用了Sticky的策略，如果在给一个生产者分配了一个分区后，会尽可能一直使用这个分区。等待该分区的batch.size（默认16K）已满，或者这个分区的消息已完成<code>linger.ms</code>（默认0毫秒，表示如果batch.size迟迟没有满后的等待时间）后批量发送消息，之后重新选择分区。</p><p><code>RoundRobinPartitioner</code>是在各个Partition中进行轮询发送，这种方式没有考虑到消息大小以及各个Broker性能差异，用得比较少。</p><p>另外可以自行指定一个Partitioner实现类，定制分区逻辑。在Partitioner接口中，核心要实现的就是<code>partition</code>方法。根据相关信息，选择一个Partition。比如用key对partition的个数取模之类的。而Topic下的所有Partition信息都在cluster参数中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取所有的Partition信息。</span></span><br><span class="line">List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 默认的BuiltInPartitioner</span></span><br><span class="line">BuiltInPartitioner.partitionForKey(serializedKey, cluster.partitionsForTopic(record.topic()).size());</span><br><span class="line"></span><br><span class="line"><span class="comment">// RoundRobinPartitioner</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(String topic, Object key, <span class="type">byte</span>[] keyBytes, Object value, <span class="type">byte</span>[] valueBytes, Cluster cluster)</span> &#123;</span><br><span class="line">    <span class="type">int</span> <span class="variable">nextValue</span> <span class="operator">=</span> nextValue(topic);</span><br><span class="line">    List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">    <span class="comment">// 具体实现</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="消费绑定">消费绑定</h3><p>消费者端可以使用<code>ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG</code>参数来指定个性化的分配策略。查看抽象类<code>AbstractPartitionAssignor</code>的实现类，可以看到Kafka默认实现了4种策略：</p><ul><li>RangeAssignor：范围策略，比如一个Topic有10个Partiton（partition 0~9），一个消费者组下有三个 Consumer（consumer1<sub>3）。Range策略就会将分区0</sub>3分给一个Consumer，4<sub>6给一个Consumer，7</sub>9给一个Consumer。</li><li>RoundRobinAssignor：轮询分配策略，可以理解为在Consumer中一个一个轮流分配分区。比如0，3，6，9分区给一个Consumer，1，4，7分区给一个Consumer，然后2，5，8给一个Consumer。</li><li>StickyAssignor：粘性策略，第一，在开始分区时，尽量保持分区的分配均匀。比如按照Range策略分（这一步实际上是随机的）。 第二、分区的分配尽可能的与上一次分配的保持一致。比如在range分区的情况下，第三个Consumer的服务宕机了，那么按照sticky策略，就会保持consumer1和consumer2原有的分区分配情况。然后将consumer3分配的7~9分区尽量平均的分配到另外两个consumer上。这种粘性策略可以很好的保持Consumer的数据稳定性，不需要将所有的Comsumer重新分配。</li></ul><p>默认情况下，Kafka使用了RangeAssignor，CooperativeStickyAssignor两种分配策略。同时我们也可以实现<code>AbstractPartitionAssignor</code>类来个性化分配。比如，我们在配置消费者服务器时性能差异明显，那么我们就可以让性能比较高的消费者处理更多的分区消息。这些各种实现最终的目的都是为了消费者更均匀的消费，提高整体的消费速度。</p><h2 id="生产者消息缓存机制">生产者消息缓存机制</h2><p>生产者在对消息分区完成之后，就要准备向服务端发送消息了，为了提升发送消息的速度，Kafka的发送的时候也做了优化。</p><p>类似于后端执行sql时使用批处理一下，为了减少段时间的网络请求次数，在短时间内发往Kafka的消息会被缓存起来一起批量发送。这种缓存并批量发送的方法在高并发的设计中非常常见。</p><p>具体在Kafka客户端中，负责实现这部分功能的是KafkaProducer里的<code>accumulator</code>和<code>sender</code>组件。</p><h3 id="accumulator缓存">accumulator缓存</h3><p><code>accumulator</code>是发送的累加器，发送消息都会在这里面缓存起来。在<code>KafkaProducer</code>类的构造方法里，可以看到对<code>accumulator</code>的初始化，其中<code>batchSize</code>表示批量发送（缓存）的最多消息数量。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// As per Kafka producer configuration documentation batch.size may be set to 0 to explicitly disable</span></span><br><span class="line"><span class="comment">// batching which in practice actually means using a batch size of 1.</span></span><br><span class="line"><span class="type">int</span> <span class="variable">batchSize</span> <span class="operator">=</span> Math.max(<span class="number">1</span>, config.getInt(ProducerConfig.BATCH_SIZE_CONFIG));</span><br><span class="line"><span class="built_in">this</span>.accumulator = <span class="keyword">new</span> <span class="title class_">RecordAccumulator</span>(logContext,</span><br><span class="line">                                         batchSize,</span><br><span class="line">                                         <span class="built_in">this</span>.compressionType,</span><br><span class="line">                                         lingerMs(config),</span><br><span class="line">                                         retryBackoffMs,</span><br><span class="line">                                         retryBackoffMaxMs,</span><br><span class="line">                                         deliveryTimeoutMs,</span><br><span class="line">                                         partitionerConfig,</span><br><span class="line">                                         metrics,</span><br><span class="line">                                         PRODUCER_METRIC_GROUP_NAME,</span><br><span class="line">                                         time,</span><br><span class="line">                                         apiVersions,</span><br><span class="line">                                         transactionManager,</span><br><span class="line">                                         <span class="keyword">new</span> <span class="title class_">BufferPool</span>(<span class="built_in">this</span>.totalMemorySize, batchSize, metrics, time, PRODUCER_METRIC_GROUP_NAME));</span><br></pre></td></tr></table></figure><p>在分区的实现类完成分区之后，会调用<code>org.apache.kafka.clients.producer.internals.RecordAccumulator#append</code>方法，使用<code>accumulator</code>组件把消息添加到缓存中。</p><p>在<code>accumulator</code>中，根据每一个Partition维护一个Deque来保存消息：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Deque&lt;ProducerBatch&gt; dq = topicInfo.batches.computeIfAbsent(effectivePartition, k -&gt; <span class="keyword">new</span> <span class="title class_">ArrayDeque</span>&lt;&gt;());</span><br></pre></td></tr></table></figure><p>每个Deque就会存放对应所有的发送批次，也就是一个或多个<code>ProducerBatch</code>。有一条消息需要被发送时，会加到Deque中的某个<code>ProducerBatch</code>的<code>recordsBuilder</code>变量的<code>DataOutputStream</code>中，最终被<code>sender</code>组件发送。以下是<code>ProducerBatch</code>类中调用<code>org.apache.kafka.common.record.MemoryRecordsBuilder#append(long, byte[], byte[], org.apache.kafka.common.header.Header[])</code>方法添加具体消息的代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">appendDefaultRecord</span><span class="params">(<span class="type">long</span> offset, <span class="type">long</span> timestamp, ByteBuffer key, ByteBuffer value,</span></span><br><span class="line"><span class="params">                                 Header[] headers)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    ensureOpenForRecordAppend();</span><br><span class="line">    <span class="type">int</span> <span class="variable">offsetDelta</span> <span class="operator">=</span> (<span class="type">int</span>) (offset - baseOffset);</span><br><span class="line">    <span class="type">long</span> <span class="variable">timestampDelta</span> <span class="operator">=</span> timestamp - baseTimestamp;</span><br><span class="line">    <span class="comment">// 使用DefaultRecord往appendStream中写入key和value</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">sizeInBytes</span> <span class="operator">=</span> DefaultRecord.writeTo(appendStream, offsetDelta, timestampDelta, key, value, headers);</span><br><span class="line">    recordWritten(offset, timestamp, sizeInBytes);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在<code>accumulator</code>的设置中，有几个变量值得注意一下。<code>ProducerConfig.BUFFER_MEMORY_CONFIG</code>用来设置整个<code>accumulator</code>的缓存大小，可以在构建<code>RecordAccumulator</code>的时候看到我们使用了这个参数。而另一个使用的参数<code>BATCH_SIZE_CONFIG</code>就是指定了每一个<code>ProducerBatch</code>的大小，在一个<code>ProducerBatch</code>中的消息的总大小要超过这个值时就会触发发送。</p><p>接下来，<code>sender</code>就是<code>KafkaProducer</code>中用来发送消息的一个单独的线程。从这里可以看到，每个 <code>KafkaProducer</code>对象都对应一个<code>sender</code>线程。他会负责将<code>RecordAccumulator</code>中的消息发送给Kafka。</p><h3 id="sender发送器">sender发送器</h3><p><code>sender</code>是用来把<code>accumulator</code>中的消息发送到Kafka的执行器，是一个独立于Producer的线程，每一个Producer都会有一个sender。在<code>KafkaProducer</code>类的构造方法里，可以看到对<code>sender</code>的初始化。因为<code>sender</code>是最终与服务端交互的，可以看到初始化的参数中有服务端的相关信息：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">List&lt;InetSocketAddress&gt; addresses = ClientUtils.parseAndValidateAddresses(config);</span><br><span class="line"><span class="keyword">if</span> (metadata != <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="built_in">this</span>.metadata = metadata;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.metadata = <span class="keyword">new</span> <span class="title class_">ProducerMetadata</span>(retryBackoffMs,</span><br><span class="line">                                         retryBackoffMaxMs,</span><br><span class="line">                                         config.getLong(ProducerConfig.METADATA_MAX_AGE_CONFIG),</span><br><span class="line">                                         config.getLong(ProducerConfig.METADATA_MAX_IDLE_CONFIG),</span><br><span class="line">                                         logContext,</span><br><span class="line">                                         clusterResourceListeners,</span><br><span class="line">                                         Time.SYSTEM);</span><br><span class="line">    <span class="built_in">this</span>.metadata.bootstrap(addresses);</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">this</span>.errors = <span class="built_in">this</span>.metrics.sensor(<span class="string">&quot;errors&quot;</span>);</span><br><span class="line"><span class="built_in">this</span>.sender = newSender(logContext, kafkaClient, <span class="built_in">this</span>.metadata);</span><br></pre></td></tr></table></figure><p><code>sender</code>也并不是一次就把<code>RecordAccumulator</code>中缓存的所有消息都发送出去，而是每次只拿一部分消息。他只获取<code>RecordAccumulator</code>中缓存内容达到<code>BATCH_SIZE_CONFIG</code>大小的<code>ProducerBatch</code>消息。当然，如果消息比较少，<code>ProducerBatch</code>中的消息大小长期达不到<code>BATCH_SIZE_CONFIG</code>的话，<code>sender</code>也不会一直等待，最多等待<code>LINGER_MS_CONFIG</code>时长，然后就会将<code>ProducerBatch</code>中的消息读取出来。</p><p>因为<code>Sender</code>类是一个单独的线程，所以必然继承了Thread类或Runable接口，我们可以在<code>Sender</code>类中找到<code>run</code>方法查看其具体的实现逻辑。</p><p>在<code>org.apache.kafka.clients.producer.internals.Sender#runOnce</code>方法中，调用了<code>org.apache.kafka.clients.producer.internals.Sender#sendProducerData</code>方法。该方法中调用<code>accumulator</code>的<code>ready</code>方法判断哪些partitions是已经准备好的，再调用<code>drain</code>方法获取对应所有准备好的<code>ProducerBatch</code>，把这些<code>ProducerBatch</code>加入到<code>inflightBatchList</code>变量中等待发送：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="type">long</span> <span class="title function_">sendProducerData</span><span class="params">(<span class="type">long</span> now)</span> &#123;</span><br><span class="line">    <span class="comment">// get the list of partitions with data ready to send</span></span><br><span class="line">    RecordAccumulator.<span class="type">ReadyCheckResult</span> <span class="variable">result</span> <span class="operator">=</span> <span class="built_in">this</span>.accumulator.ready(metadata, now);</span><br><span class="line">    <span class="comment">// 省略...</span></span><br><span class="line">    <span class="comment">// create produce requests</span></span><br><span class="line">    Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; batches = <span class="built_in">this</span>.accumulator.drain(metadata, result.readyNodes, <span class="built_in">this</span>.maxRequestSize, now);</span><br><span class="line">    <span class="comment">// 加入inflightBatchList</span></span><br><span class="line">    addToInflightBatches(batches);</span><br><span class="line">    <span class="comment">// 省略...</span></span><br><span class="line">    <span class="comment">// 执行发送</span></span><br><span class="line">    sendProduceRequests(batches, now);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后加入到<code>inflightBatchList</code>变量的消息在<code>sendProduceRequests</code>方法中交给<code>KafkaClient client</code>这个selector去执行发送。</p><p>因为<code>sender</code>是独立线程，所以每次Producer执行<code>doSend()</code>方法最后都会在需要发送的时候调用<code>this.sender.wakeup();</code>方法去触发selector的发送。</p><p>Kafka的生产者缓存机制是Kafka面对海量消息时非常重要的优化机制。合理优化这些参数，对于Kafka集群性能提升是非常重要的。比如，如果你的消息体比较大，那么应该考虑加大<code>batch.size</code>，尽量提升batch的缓存效率。而如果Producer要发送的消息确实非常多，那么就需要考虑加大<code>total.memory</code>参数，尽量避免缓存不够造成的阻塞。如果发现生产者发送消息比较慢，那么可以考虑提升<code>max.in.flight.requests.per.connection</code>参数，这样能加大消息发送的吞吐量。</p><h2 id="发送应答机制">发送应答机制</h2><p>和其他消息队列一样，生产者发送的消息需要应答机制才可以确保消息被正确的发送到服务端。</p><p>我们在上一小节介绍<code>sender</code>组件的代码中可以看到，初始化<code>sender</code>传入了一个<code>ack</code>参数，这个是获取的配置项<code>acks</code>的值。官方在<code>ProducerConfig#ACKS_DOC</code>中给出了相当详细的说明：</p><ul><li>acks=0：生产者不关心Broker是否将消息写入Partition，只管发送消息。此时的吞吐量最高，但是数据安全性最低。</li><li>acks=all/-1：生产者需要等Broker端所有的Partition（Leader和Follower）都写完了消息才会返回结果，此时数据安全性最高，但是每次发送消息需要等待更长的时间。</li><li>acks=1，折中的方案。Broker在Leader Partition写成功数据之后返回结果。</li></ul><p><em>我们在acks为0的时候，无法从RecordMetadata获取offset信息。</em></p><p>在生产环境中，acks=0的可靠性太差，基本不使用。acks=1一般用于日志传输，允许个别数据丢失但是吞吐量巨大的场景。acks=-1一般用于金融相关的敏感数据，必须保证数据安全性。</p><p>如果acks=-1，Kafka也不是强制所有的Partition都写完下次才会返回结果，根据Broker配置文件<code>broker.conf</code>中的参数<code>min.insync.replicas</code>，控制Broker在写入多少个Partition之后给Producer响应。</p><h2 id="生产者消息幂等性">生产者消息幂等性</h2><p>在<code>ProducerConfig#ACKS_DOC</code>中，最后一句写到：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Note that enabling idempotence requires this config value to be &#x27;all&#x27;.</span><br><span class="line">If conflicting configurations are set and idempotence is not explicitly enabled, idempotence is disabled.</span><br></pre></td></tr></table></figure><p>其中<code>idempotence</code>就是幂等性。当acks=-1或1时，Producer每次发送消息都是需要获取Broker端返回的RecordMetadata的。如果要保证消息安全，那么对于每次消息的传递，发送给Broker和返回给Producer两次网络传输必须是幂等的。如果Producer没有接收到Broker的返回，那么就会认为这条消息发送失败，此时Producer就会根据重试次数（参数<code>ProducerConfig.RETRIES_CONFIG</code>）进行重发。此时就可能出现消息被重复发送到Broker的问题，那么Kafka是如何解决的呢？</p><p>我们先查看一下幂等性相关的属性：</p><p><code>ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG</code>：如果设置为<code>true</code>则开启幂等性，能够保证消息发送到Broker只有一份。</p><p>这里的只有一份官方解释的英文用的是<code>exactly one</code>。相应的，分布式数据传递过程中有三种数据语义：<code>at-least-once</code>：至少一次；<code>at-most-once</code>：最多一次；<code>exactly once</code>：精确一次。</p><p>从字面意思可以知道，最多一次和至少一次都是不精确的，在部分业务场景下是可以使用的，并且只实现一种相对比较简单。但是对于一些敏感数据，必须要求不重复也不丢失，此时就需要去实现精确一次。</p><p>在Kafka中<code>at-most-once</code>可以通过<code>ack=0</code>实现，<code>at-least-once</code>可以通过<code>ack=-1</code>实现，<code>exactly once</code>就需要设置<code>idempotence</code>为<code>true</code>实现。</p><p>为了实现<code>exactly-once</code>，Kafka做了以下几个设计：</p><ul><li>PID：对于每一个Producer在初始化过程中会被分配一个唯一的PID。</li><li>SN：Sequence Number。对于每一个PID，这个Producer针对Partition会维护一个SN。这是一个从0开始单调递增的数字。当Producer要往同一个Partition发送消息时，这个SN就会加1。然后会随着消息一起发往Broker。</li><li>Broker端则会针对每个&lt;PID,Partition&gt;维护一个序列号（SN），只有当对应的SequenceNumber = SN+1时，Broker才会接收消息，同时将SN更新为SN+1。否则，SequenceNumber过小就认为消息已经写入了，不需要再重复写入，直接应答即可。而如果SequenceNumber过大，就会认为中间可能有数据丢失了。对生产者就会抛出一个OutOfOrderSequenceException。</li></ul><p>所以Kafka在打开<code>idempotence</code>之后，Broken就会保证一条消息最多只保存一条，实现<code>at-most-once</code>，再加上acks=1或-1可以实现<code>at-least-once</code>，这样就整体上保证了<code>exactly-once</code>。</p><h2 id="生产者消息事务">生产者消息事务</h2><p>消息幂等性可以保证一条消息发送到对应的Partition是安全的，那么如果是多条消息要发送到不同的Partition，此时要保证这一组消息的原子性，即全部成功才成功，就需要用到事务。</p><p>使用事务的英文<code>transaction</code>可以在<code>KafkaProducer</code>类中搜到如下几个方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1 初始化事务</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">initTransactions</span><span class="params">()</span>;</span><br><span class="line"><span class="comment">// 2 开启事务</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">beginTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException;</span><br><span class="line"><span class="comment">// 3 提交事务</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">commitTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException;</span><br><span class="line"><span class="comment">// 4 放弃事务（类似于回滚事务的操作）</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">abortTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException;</span><br></pre></td></tr></table></figure><p>其中在<code>initTransactions</code>方法的说明中，官方写到如果要使用事务，那么必须给生产者设置<code>transactional.id</code>。如果当前一个Producer的事务没有提交，而另一个新的Producer保持相同的<code>transactional.id</code>，这时旧的生产者会立即失效，无法继续发送消息。如果当前一个Producer宕机了但是事务没有提交，新的<code>transaction.id</code>相同的Producer会对旧事务补齐，要么提交事务，要么终止事务。这样新的Producer就可以继续正常工作。</p><p>所以，使用以下的方法去发送消息是比较安全的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyTransactionProducer</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">BOOTSTRAP_SERVERS</span> <span class="operator">=</span> <span class="string">&quot;192.168.56.100:9092,192.168.56.101:9092,192.168.56.102:9092&quot;</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">TOPIC</span> <span class="operator">=</span> <span class="string">&quot;test-java-client&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">//PART1:设置发送者相关属性</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        <span class="comment">// 此处配置的是kafka的端口</span></span><br><span class="line">        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);</span><br><span class="line">        props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, <span class="string">&quot;com.zm.basic.MyInterceptor&quot;</span>);</span><br><span class="line">        <span class="comment">// 配置transaction.id</span></span><br><span class="line">        props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, <span class="string">&quot;id_1&quot;</span>);</span><br><span class="line">        <span class="comment">// 配置key的序列化类</span></span><br><span class="line">        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        <span class="comment">// 配置value的序列化类</span></span><br><span class="line">        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        Producer&lt;String, String&gt; producer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(props);</span><br><span class="line">        <span class="comment">// 开启事务</span></span><br><span class="line">        producer.initTransactions();</span><br><span class="line">        producer.beginTransaction();</span><br><span class="line">        <span class="type">CountDownLatch</span> <span class="variable">latch</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CountDownLatch</span>(<span class="number">5</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">                <span class="comment">//Part2:构建消息</span></span><br><span class="line">                ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(TOPIC, Integer.toString(i), <span class="string">&quot;MyProducer&quot;</span> + i);</span><br><span class="line">                <span class="comment">//Part3:发送消息</span></span><br><span class="line">                producer.send(record);</span><br><span class="line">                System.out.println(<span class="string">&quot;message &quot;</span> + i + <span class="string">&quot; sent&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            producer.commitTransaction();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            producer.abortTransaction();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">finally</span> &#123;</span><br><span class="line">            producer.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生产者的事务消息机制保证了Producer发送消息的安全性，但是，他并不保证已经提交的消息就一定能被所有消费者消费。</p><h1 id="springboot集成kafka">SpringBoot集成Kafka</h1><p>这部分的应用本来就非常简单，而且他的本质也是在框架中构建Producer和Consumer。当了解了 kafka的核心消息流转流程，对这些应用参数就可以进行合理的组装。</p><h2 id="pom中引用kafka">pom中引用Kafka</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="配置springboot配置文件">配置springboot配置文件</h2><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring.application.name</span>=<span class="string">springboot-client</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">###########Kafka集群###########</span></span><br><span class="line"><span class="attr">spring.kafka.bootstrap-servers</span>=<span class="string">192.168.56.100:9092,192.168.56.101:9092,192.168.56.102:9092</span></span><br><span class="line"><span class="comment">###########生产者配置?###########</span></span><br><span class="line"><span class="comment"># 重试次数</span></span><br><span class="line"><span class="attr">spring.kafka.producer.retries</span>=<span class="string">0 </span></span><br><span class="line"><span class="comment"># 应答级别ack(0或1或all/-1)</span></span><br><span class="line"><span class="attr">spring.kafka.producer.acks</span>=<span class="string">1</span></span><br><span class="line"><span class="comment"># 批量发送的大小</span></span><br><span class="line"><span class="attr">spring.kafka.producer.batch-size</span>=<span class="string">16384</span></span><br><span class="line"><span class="comment"># 提交延时</span></span><br><span class="line"><span class="attr">spring.kafka.producer.properties.linger.ms</span>=<span class="string">0</span></span><br><span class="line"><span class="comment"># 缓冲区大小</span></span><br><span class="line"><span class="attr">spring.kafka.producer.buffer-memory</span> = <span class="string">33554432</span></span><br><span class="line"><span class="comment"># Kafka提供的序列化和反序列化类</span></span><br><span class="line"><span class="attr">spring.kafka.producer.keyserializer</span>=<span class="string">org.apache.kafka.common.serialization.StringSerializer</span></span><br><span class="line"><span class="attr">spring.kafka.producer.valueserializer</span>=<span class="string">org.apache.kafka.common.serialization.StringSerializer</span></span><br><span class="line"><span class="comment">###########【消费者配置】###########</span></span><br><span class="line"><span class="comment"># 默认的消费组ID</span></span><br><span class="line"><span class="attr">spring.kafka.consumer.properties.group.id</span>=<span class="string">defaultConsumerGroup</span></span><br><span class="line"><span class="comment"># 是否自动提交offset</span></span><br><span class="line"><span class="attr">spring.kafka.consumer.enable-auto-commit</span>=<span class="string">true</span></span><br><span class="line"><span class="comment"># 提交offset延时(接收到消息后多久提交offset)</span></span><br><span class="line"><span class="attr">spring.kafka.consumer.auto-commit-interval</span>=<span class="string">1000</span></span><br><span class="line"><span class="comment"># 当kafka中没有初始offset或offset超出范围时将自动重置offset</span></span><br><span class="line"><span class="comment"># earliest:重置为分区中最小的offset;</span></span><br><span class="line"><span class="comment"># latest:重置为分区中最新的offset(消费分区中新产生的数据);</span></span><br><span class="line"><span class="comment"># none:只要有一个分区不存在已提交的offset,就抛出异常;</span></span><br><span class="line"><span class="attr">spring.kafka.consumer.auto-offset-reset</span>=<span class="string">latest</span></span><br><span class="line"><span class="comment"># 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)</span></span><br><span class="line"><span class="attr">spring.kafka.consumer.properties.session.timeout.ms</span>=<span class="string">120000</span></span><br><span class="line"><span class="comment"># 消费请求超时时间</span></span><br><span class="line"><span class="attr">spring.kafka.consumer.properties.request.timeout.ms</span>=<span class="string">180000</span></span><br><span class="line"><span class="comment"># Kafka提供的序列化和反序列化类</span></span><br><span class="line"><span class="attr">spring.kafka.consumer.keydeserializer</span>=<span class="string">org.apache.kafka.common.serialization.StringDeserializer</span></span><br><span class="line"><span class="attr">spring.kafka.consumer.valuedeserializer</span>=<span class="string">org.apache.kafka.common.serialization.StringDeserializer</span></span><br></pre></td></tr></table></figure><p>这些配置文件在基础的客户端中其实都可以找到对应的说明，在学习了基础的之后再学习配置并不难。</p><h2 id="应用中使用框架注入的kafkatemplate发送消息">应用中使用框架注入的KafkaTemplate发送消息</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyProducer</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> KafkaTemplate&lt;String, Object&gt; kafkaTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">MyProducer</span><span class="params">(KafkaTemplate&lt;String, Object&gt; kafkaTemplate)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.kafkaTemplate = kafkaTemplate;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/kafka/normal/&#123;message&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sendMessage1</span><span class="params">(<span class="meta">@PathVariable(&quot;message&quot;)</span> String normalMessage)</span> &#123;</span><br><span class="line">        kafkaTemplate.send(<span class="string">&quot;topic1&quot;</span>, normalMessage);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="使用kafkalistener注解声明消息消费者">使用@KafkaListener注解声明消息消费者</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyConsumer</span> &#123;</span><br><span class="line">    <span class="meta">@KafkaListener(topics = &#123;&quot;topic1&quot;&#125;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onMessage</span><span class="params">(ConsumerRecord&lt;?, ?&gt; record)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;消费消息：&quot;</span> + record.topic() + <span class="string">&quot;-&quot;</span> + record.partition() + <span class="string">&quot;-&quot;</span> + record.value());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div><div style="text-align:center;color:#ccc;font-size:14px">-------------　　　　本文结束　<i class="fa fa-flag"></i>　感谢阅读　　　　-------------</div></div><div class="reward-container"><div>请我一杯咖啡吧！</div> <button> 打赏</button><div class="post-reward"><div> <img src="https://myblog-1303447677.file.myqcloud.com/BlogFrame/wechatpay.png" alt=" 微信支付"> <span>微信支付</span></div><div> <img src="https://myblog-1303447677.file.myqcloud.com/BlogFrame/alipay.png" alt=" 支付宝"> <span>支付宝</span></div></div></div><div class="post-copyright"><ul><li class="post-copyright-author"></li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://zm6666.top/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6Distribute-framework/How-to-use-Kafka-2-Java_Client/" title="Kafka使用指南2——Java客户端以及Spring集成">https://zm6666.top/分布式框架Distribute-framework/How-to-use-Kafka-2-Java_Client/</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="post-tags"><a href="/tags/Java/" rel="tag"><i class="fa fa-tag"></i> Java</a><a href="/tags/Kafka/" rel="tag"><i class="fa fa-tag"></i> Kafka</a></div><div class="post-nav"><div class="post-nav-item"><a href="/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6Distribute-framework/How-to-use-Kafka-3-Cluster/" rel="prev" title="Kafka使用指南3——Kafka集群架构设计"><i class="fa fa-angle-left"></i> Kafka使用指南3——Kafka集群架构设计</a></div><div class="post-nav-item"> <a href="/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6Distribute-framework/How-to-use-Kafka-4-Log_Index/" rel="next" title="Kafka使用指南4——Kafka日志索引分析">Kafka使用指南4——Kafka日志索引分析<i class="fa fa-angle-right"></i></a></div></div></footer></article></div><div class="comments utterances-container"></div></div></main><footer class="footer"><div class="footer-inner"><div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">苏ICP备2022038238号-1</a></div><div class="copyright"> &copy; 2019 – <span itemprop="copyrightYear">2024</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">zm</span></div><div class="busuanzi-count"><span class="post-meta-item" id="busuanzi_container_site_uv"><span class="post-meta-item-icon"><i class="fa fa-user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span><span class="post-meta-item" id="busuanzi_container_site_pv"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div><div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动</div><script>var titleTime,OriginTitle=document.title;document.addEventListener("visibilitychange",function(){document.hidden?(document.title="来啊快活啊~"+OriginTitle,clearTimeout(titleTime)):(document.title="咚咚咚"+OriginTitle,titleTime=setTimeout(function(){document.title=OriginTitle},2e3))})</script></div></footer><div class="back-to-top" role="button" aria-label="返回顶部"><i class="fa fa-arrow-up fa-lg"></i> <span>0%</span></div><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script><script src="/js/third-party/search/local-search.js"></script><script src="/js/third-party/pace.js"></script><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script class="next-config" data-name="leancloud_visitors" type="application/json">{"enable":true,"app_id":"WYpTHDdtwSPYrGnPn3Dd6VK8-gzGzoHsz","app_key":"167XRDBA8P2enbdqnG3050K1","server_url":"https://wypthddt.lc-cn-n1-shared.com","security":true,"betterPerformance":true}</script><script src="/js/third-party/statistics/lean-analytics.js"></script><script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script><script src="/js/third-party/math/mathjax.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script><script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://zm6666.top/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6Distribute-framework/How-to-use-Kafka-2-Java_Client/"}</script><script src="/js/third-party/quicklink.js"></script><script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"zhaomin6666/BlogUtterances","issue_term":"title","theme":"github-light"}</script><script src="/js/third-party/comments/utterances.js"></script></body></html>
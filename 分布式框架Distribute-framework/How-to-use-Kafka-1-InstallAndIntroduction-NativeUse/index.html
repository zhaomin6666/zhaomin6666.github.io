<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222" media="(prefers-color-scheme: light)"><meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.0.0"><link rel="apple-touch-icon" sizes="180x180" href="https://myblog-1303447677.file.myqcloud.com/BlogFrame/pig_32px_1271682_easyicon.net.ico"><link rel="icon" type="image/png" sizes="32x32" href="https://myblog-1303447677.file.myqcloud.com/BlogFrame/pig_32px_1271682_easyicon.net.ico"><link rel="icon" type="image/png" sizes="16x16" href="https://myblog-1303447677.file.myqcloud.com/BlogFrame/pig_32px_1271682_easyicon.net.ico"><link rel="mask-icon" href="https://myblog-1303447677.file.myqcloud.com/BlogFrame/pig_32px_1271682_easyicon.net.ico" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://cdn.jsdmirror.com/npm/@fortawesome/fontawesome-free@6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdmirror.com/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdmirror.com/npm/pace-js@1.2.4/themes/black/pace-theme-minimal.css"><script src="https://cdn.jsdmirror.com/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script><script class="next-config" data-name="main" type="application/json">{"hostname":"zm6666.top","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":"utterances","storage":true,"lazyload":false,"nav":null,"activeClass":"utterances"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="https://cdn.jsdmirror.com/npm/hexo-theme-next@8.18.2/source/js/config.min.js"></script><meta name="description" content="目录  Kafka简介和安装以及原生命令行客户端（本篇） 这块主要是一个Kafka所包含的内部元素的介绍以及简单的使用。 Java客户端以及Spring集成 Java客户端其实就是原生命令行的一种封装，学习如何使用即可，Spring就是在这个基础上再进行了对象的管理，使用起来并不难。 Kafka集群架构设计 Kafka在设计之初就是为了高吞吐、高性能、高可扩展，所以它的集群架构是"><meta property="og:type" content="article"><meta property="og:title" content="Kafka使用指南1——简介和安装、原生命令行的使用"><meta property="og:url" content="https://zm6666.top/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6Distribute-framework/How-to-use-Kafka-1-InstallAndIntroduction-NativeUse/index.html"><meta property="og:site_name" content="Oli的生活杂谈"><meta property="og:description" content="目录  Kafka简介和安装以及原生命令行客户端（本篇） 这块主要是一个Kafka所包含的内部元素的介绍以及简单的使用。 Java客户端以及Spring集成 Java客户端其实就是原生命令行的一种封装，学习如何使用即可，Spring就是在这个基础上再进行了对象的管理，使用起来并不难。 Kafka集群架构设计 Kafka在设计之初就是为了高吞吐、高性能、高可扩展，所以它的集群架构是"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2024-04-01T15:00:21.000Z"><meta property="article:modified_time" content="2024-06-02T14:15:34.692Z"><meta property="article:tag" content="Java"><meta property="article:tag" content="Kafka"><meta name="twitter:card" content="summary"><link rel="canonical" href="https://zm6666.top/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6Distribute-framework/How-to-use-Kafka-1-InstallAndIntroduction-NativeUse/"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://zm6666.top/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6Distribute-framework/How-to-use-Kafka-1-InstallAndIntroduction-NativeUse/","path":"分布式框架Distribute-framework/How-to-use-Kafka-1-InstallAndIntroduction-NativeUse/","title":"Kafka使用指南1——简介和安装、原生命令行的使用"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>Kafka使用指南1——简介和安装、原生命令行的使用 | Oli的生活杂谈</title><script src="https://cdn.jsdmirror.com/npm/hexo-theme-next@8.18.2/source/js/third-party/analytics/baidu-analytics.min.js"></script><script async src="https://hm.baidu.com/hm.js?a2fa2913e1140bc40e9aef85d103226c"></script><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript></head><body itemscope itemtype="http://schema.org/WebPage" class="use-motion"><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span><span class="toggle-line"></span><span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">Oli的生活杂谈</p><i class="logo-line"></i></a></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%9B%AE%E5%BD%95"><span class="nav-number">1.</span> <span class="nav-text">目录</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9"><span class="nav-number">2.</span> <span class="nav-text">主要内容</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#kafka%E7%AE%80%E4%BB%8B%E5%92%8C%E5%AE%89%E8%A3%85"><span class="nav-number">3.</span> <span class="nav-text">Kafka简介和安装</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AE%80%E4%BB%8B"><span class="nav-number">3.1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">3.2.</span> <span class="nav-text">应用场景</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86"><span class="nav-number">3.2.1.</span> <span class="nav-text">日志收集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F"><span class="nav-number">3.2.2.</span> <span class="nav-text">消息系统</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%A8%E6%88%B7%E6%B4%BB%E5%8A%A8%E8%B7%9F%E8%B8%AA"><span class="nav-number">3.2.3.</span> <span class="nav-text">用户活动跟踪</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kafka%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="nav-number">3.2.4.</span> <span class="nav-text">Kafka基本概念</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%8A%82%E7%82%B9broker"><span class="nav-number">3.2.4.1.</span> <span class="nav-text">节点Broker</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%BB%E9%A2%98topic"><span class="nav-number">3.2.4.2.</span> <span class="nav-text">主题Topic</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85producer"><span class="nav-number">3.2.4.3.</span> <span class="nav-text">生产者Producer</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85consumer"><span class="nav-number">3.2.4.4.</span> <span class="nav-text">消费者Consumer</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84consumergroup"><span class="nav-number">3.2.4.5.</span> <span class="nav-text">消费者组ConsumerGroup</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E5%8C%BApartition"><span class="nav-number">3.2.4.6.</span> <span class="nav-text">分区Partition</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kafka%E5%AE%89%E8%A3%85"><span class="nav-number">3.3.</span> <span class="nav-text">Kafka安装</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BE%9D%E8%B5%96%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85"><span class="nav-number">3.3.1.</span> <span class="nav-text">依赖环境安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%89%E8%A3%85kafka"><span class="nav-number">3.3.2.</span> <span class="nav-text">安装Kafka</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2"><span class="nav-number">3.3.3.</span> <span class="nav-text">集群部署</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8"><span class="nav-number">4.</span> <span class="nav-text">简单使用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E4%B8%BB%E9%A2%98"><span class="nav-number">4.1.</span> <span class="nav-text">创建主题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF"><span class="nav-number">4.2.</span> <span class="nav-text">发送消息</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8E%A5%E6%94%B6%E6%B6%88%E6%81%AF"><span class="nav-number">4.3.</span> <span class="nav-text">接收消息</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E5%A4%9A%E4%B8%BB%E9%A2%98"><span class="nav-number">4.4.</span> <span class="nav-text">消费多主题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E6%92%AD%E6%B6%88%E8%B4%B9"><span class="nav-number">4.5.</span> <span class="nav-text">多播消费</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC%E7%9A%84%E7%90%86%E8%A7%A3"><span class="nav-number">5.</span> <span class="nav-text">分区、副本的理解</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E5%8C%BA"><span class="nav-number">5.1.</span> <span class="nav-text">分区</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%AF%E6%9C%AC"><span class="nav-number">5.2.</span> <span class="nav-text">副本</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B0%8F%E7%BB%93"><span class="nav-number">5.3.</span> <span class="nav-text">小结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E5%AE%B9%E7%81%BE"><span class="nav-number">6.</span> <span class="nav-text">集群容灾</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E7%9A%84%E7%94%9F%E4%BA%A7%E4%B8%8E%E6%B6%88%E8%B4%B9"><span class="nav-number">7.</span> <span class="nav-text">集群的生产与消费</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85"><span class="nav-number">7.1.</span> <span class="nav-text">生产者</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85"><span class="nav-number">7.2.</span> <span class="nav-text">消费者</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E9%A1%BA%E5%BA%8F"><span class="nav-number">7.3.</span> <span class="nav-text">消费顺序</span></a></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="" src="https://myblog-1303447677.file.myqcloud.com/BlogFrame/my-avatar.png"><p class="site-author-name" itemprop="name"></p><div class="site-description" itemprop="description"></div></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">24</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">6</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">19</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author animated"><span class="links-of-author-item"><a href="https://github.com/zhaomin6666" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zhaomin6666" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i> GitHub</a></span><span class="links-of-author-item"><a href="mailto:lanmao_1029@163.com" title="E-Mail → mailto:lanmao_1029@163.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i> E-Mail</a></span></div><div class="cc-license animated" itemprop="license"> <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdn.jsdmirror.com/npm/@creativecommons/vocabulary@2020.11.3/assets/license_badges/big/by_nc_sa.svg" alt="Creative Commons"></a></div></div></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zm6666.top/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6Distribute-framework/How-to-use-Kafka-1-InstallAndIntroduction-NativeUse/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="https://myblog-1303447677.file.myqcloud.com/BlogFrame/my-avatar.png"><meta itemprop="name" content=""></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Oli的生活杂谈"><meta itemprop="description" content=""></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="Kafka使用指南1——简介和安装、原生命令行的使用 | Oli的生活杂谈"><meta itemprop="description" content=""></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> Kafka使用指南1——简介和安装、原生命令行的使用</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2024-04-01 23:00:21" itemprop="dateCreated datePublished" datetime="2024-04-01T23:00:21+08:00">2024-04-01</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2024-06-02 22:15:34" itemprop="dateModified" datetime="2024-06-02T22:15:34+08:00">2024-06-02</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6Distribute-framework/" itemprop="url" rel="index"><span itemprop="name">分布式框架Distribute-framework</span></a></span></span><span id="/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6Distribute-framework/How-to-use-Kafka-1-InstallAndIntroduction-NativeUse/" class="post-meta-item leancloud_visitors" data-flag-title="Kafka使用指南1——简介和安装、原生命令行的使用" title="阅读次数"><span class="post-meta-item-icon"><i class="far fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span class="leancloud-visitors-count"></span></span></div></div></header><div class="post-body" itemprop="articleBody"><hr><h1 id="目录">目录</h1><ol type="1"><li><p>Kafka简介和安装以及原生命令行客户端（本篇）</p><p>这块主要是一个Kafka所包含的内部元素的介绍以及简单的使用。</p></li><li><p>Java客户端以及Spring集成</p><p>Java客户端其实就是原生命令行的一种封装，学习如何使用即可，Spring就是在这个基础上再进行了对象的管理，使用起来并不难。</p></li><li><p>Kafka集群架构设计</p><p>Kafka在设计之初就是为了高吞吐、高性能、高可扩展，所以它的集群架构是非常值得学习的。</p></li><li><p>Kafka日志索引详解</p><p>Broker能够高效地处理和保存消息，是Kafka高性能的保障。我们从可见的log文件入手，去研究一下Kafka是如何保证消息高效的流转。</p></li></ol><h1 id="主要内容">主要内容</h1><p>这一部分主要是接触Kafka并熟悉Kafka的使用方式。从安装搭建开始到基础使用，快速感受Kafka的功能，可以帮助理解基于Kafka的解决方案。</p><span id="more"></span><hr><h1 id="kafka简介和安装">Kafka简介和安装</h1><h2 id="简介">简介</h2><p>Kafka是最初由Linkedin公司开发，是一个分布式、支持分区的（partition）、多副本的（replica），基于zookeeper协调的分布式消息系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于hadoop的批处理系统、低延迟的实时系统、Storm/Spark流式处理引擎，web/nginx日志、访问日志，消息服务等等，用scala语言编写， Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。</p><h2 id="应用场景">应用场景</h2><h3 id="日志收集">日志收集</h3><p>公司可以利用Kafka收集各种服务的日志，通过kafka以统一接口服务的方式开放给各种consumer。</p><p>简单的架构就是nginx记录访问日志，由logstash收集日志然后将日志发送给Kafka，再由spark等大数据处理框架处理日志数据，最终以一定的形式保存到日志储存层并由应用客户端展示。</p><h3 id="消息系统">消息系统</h3><p>当做传统的消息队列使用，解耦生产者和消费者，削峰填谷。</p><h3 id="用户活动跟踪">用户活动跟踪</h3><p>和日志收集类似，只不过数据来源是各web应用或app应用记录的用户各种活动，如点击、搜索、浏览等操作。这些活动信息被各个服务器发送到kafka，然后订阅者通过订阅这些topic来做实时的监控分析，或者使用大数据模型进行离线分析和数据挖掘。</p><h3 id="kafka基本概念">Kafka基本概念</h3><p>在之前学习过RabbitMQ和RocketMQ之后，对消息队列的理解应该已经很深了。Kafka主要的特点就是分布式和分区消息存储。主要的几个概念如下：</p><h4 id="节点broker">节点Broker</h4><p>消息中间件的处理节点，一个Kafka节点就是一个broker，一个或者多个Broker可以组成一个Kafka集群。</p><h4 id="主题topic">主题Topic</h4><p>和传统消息中间件一样，主题是对消息的分类，生产者发布消息需要指定一个Topic。</p><h4 id="生产者producer">生产者Producer</h4><p>消息生产者，向Broker发送消息的客户端。</p><h4 id="消费者consumer">消费者Consumer</h4><p>消息消费者，从Broker读取消息的客户端。</p><h4 id="消费者组consumergroup">消费者组ConsumerGroup</h4><p>每个消费者属于一个特定的ConsumerGroup，一个消息可以被不同的ConsumerGroup消费，但是一个ConsumerGroup中的消费者只有一个Consumer可以消费到消息。</p><h4 id="分区partition">分区Partition</h4><p>一个Topic可以被分为多个Partition，生产者发送消息是往指定的Topic中的某一个（可以指定，不指定的话使用Hash）Partition发送消息，消费者也是从Topic中的某一个（或多个）Partition中消费消息，一个Partition最多只能被一个消费者消费。</p><p>Partition的存在是为了实现高并发，每一个Partition能够存在不同的Broker中，这样多个消费者可以从不同的Broker上消费消息。</p><h2 id="kafka安装">Kafka安装</h2><h3 id="依赖环境安装">依赖环境安装</h3><p>Kafka由Scala语言开发，运行在JVM上，所以首先需要安装Jdk：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载jdk包之后解压</span></span><br><span class="line">[root@localhost ~]<span class="comment"># tar -zxvf jdk-8u362b09-linux-x64.tar.gz -C /opt/</span></span><br><span class="line"><span class="comment"># 将/opt/jdk-8u362b09-linux-x64 建立符号链接到/usr/local/jdk</span></span><br><span class="line">[root@localhost ~]<span class="comment"># ln -s /opt/jdk1.8.0_362-b09 /usr/local/jdk</span></span><br><span class="line"><span class="comment"># 写入环境变量</span></span><br><span class="line">[root@localhost ~]<span class="comment"># echo &quot;export JAVA_HOME=/usr/local/jdk&quot; &gt;&gt; /etc/profile</span></span><br><span class="line">[root@localhost ~]<span class="comment"># echo &quot;export JRE_HOME=\$JAVA_HOME/jre&quot; &gt;&gt; /etc/profile</span></span><br><span class="line">[root@localhost ~]<span class="comment"># echo &quot;export CLASSPATH=.:\$JAVA_HOME/lib:\$JRE_HOME/lib&quot; &gt;&gt; /etc/profile</span></span><br><span class="line">[root@localhost ~]<span class="comment"># echo &quot;export PATH=\$JAVA_HOME/bin:\$PATH&quot; &gt;&gt; /etc/profile</span></span><br><span class="line"><span class="comment"># 使配置文件生效。</span></span><br><span class="line">[root@localhost ~]<span class="comment"># source /etc/profile</span></span><br><span class="line"><span class="comment"># 赋予 jdk 中 bin 文件可执行权限</span></span><br><span class="line">[root@localhost ~]<span class="comment"># chmod -R +x /usr/local/jdk/bin </span></span><br><span class="line"><span class="comment"># 安装完毕，验证</span></span><br><span class="line">[root@localhost ~]<span class="comment"># java -version</span></span><br><span class="line">openjdk version <span class="string">&quot;1.8.0_362&quot;</span></span><br><span class="line">OpenJDK Runtime Environment (Temurin)(build 1.8.0_362-b09)</span><br><span class="line">OpenJDK 64-Bit Server VM (Temurin)(build 25.362-b09, mixed mode)</span><br></pre></td></tr></table></figure><p>Kafka依赖zookeeper，所以需要安装zookeeper：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载zookeeper包之后解压</span></span><br><span class="line">[root@localhost ~]<span class="comment"># tar -zxvf apache-zookeeper-3.8.4-bin.tar.gz -C /opt/</span></span><br><span class="line">[root@localhost ~]<span class="comment"># cd /opt</span></span><br><span class="line"><span class="comment"># 在/usr/local/下创建一个不带版本号的zookeeper链接</span></span><br><span class="line">[root@localhost opt]<span class="comment"># ln -s /opt/zookeeper-3.4.11 /usr/local/zookeeper</span></span><br><span class="line">[root@localhost opt]<span class="comment"># cd /usr/local/zookeeper/conf/</span></span><br><span class="line"><span class="comment"># 依据默认的配置新建自己的配置文件</span></span><br><span class="line">[root@localhost conf]<span class="comment"># cp zoo_sample.cfg zoo.cfg</span></span><br><span class="line"><span class="comment">#配置zookeeper的数据文件和日志文件存放位置</span></span><br><span class="line">[root@localhost conf]<span class="comment"># echo -e &quot;# append zk_env\nexport PATH=$PATH:/usr/local/zookeeper/bin&quot; &gt;&gt; /etc/profile</span></span><br><span class="line">[root@localhost conf]<span class="comment"># sed -i &#x27;s/dataDir=\/tmp\/zookeeper/dataLogDir=\/usr\/local\/zookeeper\/logs\ndataDir=\/usr\/local\/zookeeper\/data/g&#x27; zoo.cfg</span></span><br><span class="line"><span class="comment"># 使配置文件生效。</span></span><br><span class="line">[root@localhost conf]<span class="comment"># source /etc/profile</span></span><br><span class="line"><span class="comment"># 新建zookeeper的日志文件和数据文件</span></span><br><span class="line">[root@localhost conf]<span class="comment"># mkdir -p /usr/local/zookeeper/&#123;logs,data&#125;</span></span><br><span class="line"><span class="comment"># 启动zookeeper</span></span><br><span class="line">[root@localhost conf]<span class="comment"># zkServer.sh start</span></span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /usr/local/zookeeper/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br></pre></td></tr></table></figure><p>注：zookeeper默认端口为2181，同时还会占用8080的管理端口。</p><h3 id="安装kafka">安装Kafka</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载kafka包之后解压</span></span><br><span class="line">[root@localhost ~]<span class="comment"># tar -xzf kafka_2.13-3.7.0.tgz /opt/kafka_2.13-3.7.0</span></span><br><span class="line">[root@localhost ~]<span class="comment"># cd /opt/kafka_2.13-3.7.0/config/</span></span><br><span class="line"><span class="comment"># 进入目录修改配置文件</span></span><br><span class="line">[root@localhost config]<span class="comment">#vim server.properties</span></span><br><span class="line"><span class="comment"># 配置文件中内容如下：</span></span><br><span class="line"> <span class="comment">#broker.id属性在kafka集群中必须要是唯一，多个broker设置为0,1,2...</span></span><br><span class="line"> broker.id=0</span><br><span class="line"> <span class="comment">#kafka部署的机器ip和提供服务的端口号</span></span><br><span class="line"> listeners=PLAINTEXT://127.0.0.1:9092</span><br><span class="line"> <span class="comment">#kafka的消息存储文件</span></span><br><span class="line"> log.dir=/usr/local/data/kafka‐logs</span><br><span class="line"> <span class="comment">#kafka连接zookeeper的地址 我这里zk和kafka在同一台上</span></span><br><span class="line"> zookeeper.connect=127.0.0.1:2181</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动Kafka 后台启动，不会打印日志到控制台</span></span><br><span class="line">[root@localhost ~] kafka-server-start.sh -daemon /usr/local/kafka/config/server.properties </span><br><span class="line"><span class="comment"># 启动后链接zookeeper验证broker的状态</span></span><br><span class="line">[root@localhost ~]<span class="comment"># zkCli.sh</span></span><br><span class="line">Connecting to localhost:2181</span><br><span class="line">...</span><br><span class="line">[zk: localhost:2181(CONNECTED) 0] <span class="built_in">ls</span> /brokers/ids</span><br><span class="line">[0] <span class="comment"># 说明broker.id为0的节点已启动</span></span><br><span class="line"><span class="comment"># 关闭Kafka</span></span><br><span class="line">[root@localhost /]<span class="comment"># kafka-server-stop.sh</span></span><br></pre></td></tr></table></figure><p>其中配置文件有大量参数可以设置，部分要点如下：</p><table><colgroup><col style="width:33%"><col style="width:33%"><col style="width:33%"></colgroup><thead><tr class="header"><th>参数名称</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr class="odd"><td>broker.id</td><td>0</td><td>每个broker都可以用一个唯一的非负整数id进行表示。可以选择任意数字作为id，只要id是唯一的即可。</td></tr><tr class="even"><td>log.dir或log.dirs</td><td>/tmp/kafka-logs</td><td>Kafka存放数据的路径。路径不是唯一的，可以是多个，路径之间只需要逗号分割。</td></tr><tr class="odd"><td>listeners</td><td>PLAINTEXT://127.0.0.1:9092</td><td>server接收客户端连接的端口，ip配置kafka本机ip即可。另外可以配置多个，如还需新增配置SSL的端口。</td></tr><tr class="even"><td>zookeeper.connect</td><td>127.0.0.1:2181</td><td>zookeeper的地址，如果是zookeeper集群则可以配置多个。如hostname1:port1, hostname2:port2, hostname3:port3。</td></tr><tr class="odd"><td>log.retention.hours</td><td>168</td><td>每个日志文件删除之前保存的时间。默认数据保存时间对所有topic都一样。</td></tr><tr class="even"><td>num.patitions</td><td>1</td><td>创建topic的默认分区数</td></tr><tr class="odd"><td>default.replication.factor</td><td>1</td><td>自动创建topic的默认副本数量，建议设置为大于等于2。副本数量需要小于等于broker的数量。</td></tr><tr class="even"><td>min.insync.replicas</td><td>1</td><td>当producer设置acks为-1时，min.insync.replicas指定需要有多少个副本写数据是成功的，才认为消息发送成功。如果无法达到该数，那么生产者会抛出异常（NotEnoughReplicas）。</td></tr></tbody></table><h3 id="集群部署">集群部署</h3><p>我们创建一个3个节点的集群，三个节点的脚本中对应的配置分别为：</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一个节点</span></span><br><span class="line"><span class="attr">broker.id</span>=<span class="string">0</span></span><br><span class="line"><span class="attr">listeners</span>=<span class="string">PLAINTEXT://0.0.0.0:9092</span></span><br><span class="line"><span class="attr">advertised.listeners</span>=<span class="string">PLAINTEXT://192.168.56.100:9092</span></span><br><span class="line"><span class="comment"># 第二个节点</span></span><br><span class="line"><span class="attr">broker.id</span>=<span class="string">1</span></span><br><span class="line"><span class="attr">listeners</span>=<span class="string">PLAINTEXT://0.0.0.0:9092</span></span><br><span class="line"><span class="attr">advertised.listeners</span>=<span class="string">PLAINTEXT://192.168.56.101:9092</span></span><br><span class="line"><span class="comment"># 第三个节点</span></span><br><span class="line"><span class="attr">broker.id</span>=<span class="string">1</span></span><br><span class="line"><span class="attr">listeners</span>=<span class="string">PLAINTEXT://0.0.0.0:9092</span></span><br><span class="line"><span class="attr">advertised.listeners</span>=<span class="string">PLAINTEXT://192.168.56.102:9092</span></span><br></pre></td></tr></table></figure><p>可以从zookeeper的数据中看到brokers有0,1,2三个节点：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 25] <span class="built_in">ls</span> /brokers/ids</span><br><span class="line">[0, 1, 2]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 26] get /brokers/ids/0</span><br><span class="line">&#123;<span class="string">&quot;features&quot;</span>:&#123;&#125;,<span class="string">&quot;listener_security_protocol_map&quot;</span>:&#123;<span class="string">&quot;PLAINTEXT&quot;</span>:<span class="string">&quot;PLAINTEXT&quot;</span>&#125;,<span class="string">&quot;endpoints&quot;</span>:[<span class="string">&quot;PLAINTEXT://192.168.56.100:9092&quot;</span>],<span class="string">&quot;jmx_port&quot;</span>:-1,<span class="string">&quot;port&quot;</span>:9092,<span class="string">&quot;host&quot;</span>:<span class="string">&quot;192.168.56.100&quot;</span>,<span class="string">&quot;version&quot;</span>:5,<span class="string">&quot;timestamp&quot;</span>:<span class="string">&quot;1711979088489&quot;</span>&#125;</span><br><span class="line">[zk: localhost:2181(CONNECTED) 27] get /brokers/ids/1</span><br><span class="line">&#123;<span class="string">&quot;features&quot;</span>:&#123;&#125;,<span class="string">&quot;listener_security_protocol_map&quot;</span>:&#123;<span class="string">&quot;PLAINTEXT&quot;</span>:<span class="string">&quot;PLAINTEXT&quot;</span>&#125;,<span class="string">&quot;endpoints&quot;</span>:[<span class="string">&quot;PLAINTEXT://192.168.56.101:9092&quot;</span>],<span class="string">&quot;jmx_port&quot;</span>:-1,<span class="string">&quot;port&quot;</span>:9092,<span class="string">&quot;host&quot;</span>:<span class="string">&quot;192.168.56.101&quot;</span>,<span class="string">&quot;version&quot;</span>:5,<span class="string">&quot;timestamp&quot;</span>:<span class="string">&quot;1711978899480&quot;</span>&#125;</span><br><span class="line">[zk: localhost:2181(CONNECTED) 28] get /brokers/ids/2</span><br><span class="line">&#123;<span class="string">&quot;features&quot;</span>:&#123;&#125;,<span class="string">&quot;listener_security_protocol_map&quot;</span>:&#123;<span class="string">&quot;PLAINTEXT&quot;</span>:<span class="string">&quot;PLAINTEXT&quot;</span>&#125;,<span class="string">&quot;endpoints&quot;</span>:[<span class="string">&quot;PLAINTEXT://192.168.56.102:9092&quot;</span>],<span class="string">&quot;jmx_port&quot;</span>:-1,<span class="string">&quot;port&quot;</span>:9092,<span class="string">&quot;host&quot;</span>:<span class="string">&quot;192.168.56.102&quot;</span>,<span class="string">&quot;version&quot;</span>:5,<span class="string">&quot;timestamp&quot;</span>:<span class="string">&quot;1711979031132&quot;</span>&#125;</span><br></pre></td></tr></table></figure><h1 id="简单使用">简单使用</h1><p>以下命令行中的命令均有大量附加的选项，如果想要查看某一个命令的详细用法，可以不带任何参数运行即可查看帮助。</p><h2 id="创建主题">创建主题</h2><p>使用以下命令创建一个名为<code>test</code>的主题，并且设置副本数为1，分区数为1，其中副本数一定要小于broker的数量：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test</span></span><br><span class="line">Created topic <span class="built_in">test</span>.</span><br></pre></td></tr></table></figure><p>注：新版本可以使用<code>--bootstrap-server</code>代替<code>--zookeeper</code>来直接指定broker的地址，因为新版本的kafka可以不依赖于zookeeper，直接使用zookeeper内置的kraft进行元数据的存放和共享。</p><p>可以通过以下命令来查看kafka中目前存在的topic：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># kafka-topics.sh --list --bootstrap-server localhost:9092</span></span><br><span class="line"><span class="built_in">test</span></span><br></pre></td></tr></table></figure><p>删除主题可以使用以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># kafka-topics.sh --delete --topic test --bootstrap-server localhost:9092</span></span><br></pre></td></tr></table></figure><h2 id="发送消息">发送消息</h2><p>使用以下命令往名为test的topic中发送两条消息，如果topic不存在会自动创建：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># kafka-console-producer.sh --broker-list localhost:9092 --topic test</span></span><br><span class="line">&gt;msg1</span><br><span class="line">&gt;msg2</span><br></pre></td></tr></table></figure><h2 id="接收消息">接收消息</h2><p>使用以下命令从名为test的topic中接收消息，使用<code>--from-beginning</code>命令从头开始消费，否则默认消费新的消息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning</span></span><br><span class="line">msg1</span><br><span class="line">msg2</span><br></pre></td></tr></table></figure><h2 id="消费多主题">消费多主题</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先往test2主题中发送两条消息</span></span><br><span class="line">[root@localhost ~]<span class="comment"># kafka-console-producer.sh --broker-list localhost:9092 --topic test2</span></span><br><span class="line">&gt;test2-1</span><br><span class="line">&gt;test2-2</span><br><span class="line"><span class="comment"># 启动消费者从test和test2主题中从头消费消息</span></span><br><span class="line">[root@localhost ~]<span class="comment"># kafka-console-consumer.sh --bootstrap-server localhost:9092 --whitelist &quot;test|test2&quot; --from-beginning</span></span><br><span class="line">test2-msg1</span><br><span class="line">test2-msg2</span><br><span class="line">msg1</span><br><span class="line">msg2</span><br><span class="line">msg3</span><br><span class="line">msg4</span><br></pre></td></tr></table></figure><h2 id="多播消费">多播消费</h2><p>实现类似于发布订阅（pub-sub）的模式，针对kafka同一条消息只能被统一消费组下的某一个消费者消费的特性，要实现多播只要保证这些消费者属于不同的消费组即可。再增加一个消费者，给其定义一个新的消费组testGroup2，这样两个消费者客户端均可消费到消息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 消费者1，使用testGroup1消费组</span></span><br><span class="line">[root@localhost ~]<span class="comment"># kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --consumer-property group.id=testGroup1</span></span><br><span class="line">msg5</span><br><span class="line"></span><br><span class="line"><span class="comment"># 消费者2，使用testGroup1消费组</span></span><br><span class="line">[root@localhost ~]<span class="comment"># kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --consumer-property group.id=testGroup1</span></span><br><span class="line"><span class="comment"># 未消费到消息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 消费者3，使用testGroup2消费组</span></span><br><span class="line">[root@localhost ~]<span class="comment"># kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --consumer-property group.id=testGroup1</span></span><br><span class="line">msg5</span><br></pre></td></tr></table></figure><p>可以使用以下命令来查看消费者的名称，可以看到我们一开始不指定消费组创建的消费者会有默认创建一个消费组：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list</span></span><br><span class="line">testGroup2</span><br><span class="line">testGroup1</span><br><span class="line">console-consumer-29003</span><br></pre></td></tr></table></figure><p>可以使用以下命令来查看消费者的消费偏移量，其中current-offset表示当前消费组已消费的偏移量，log-end-offset表示当前分区最后一条消息的偏移量，lag表示当前消费组的未消费的消息量：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group testGroup1</span></span><br><span class="line"></span><br><span class="line">GROUP       TOPIC  PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG   CONSUMER-ID                                           HOST            CLIENT-ID</span><br><span class="line">testGroup1  <span class="built_in">test</span>   0          57              57              0     console-consumer-19b01122-2844-484d-a14f-f67b57f42cc8 /127.0.0.1      console-consumer</span><br></pre></td></tr></table></figure><h1 id="分区副本的理解">分区、副本的理解</h1><h2 id="分区">分区</h2><p>我们从上面提到的消费偏移量以及消费者指定从头消费可以看出，所有的消息在一个分区中是按序存储的，所以才会有偏移量和从头消费。而每个分区是一个单独的存储空间，一个Topic是一组分区的一个类别名称。</p><table><thead><tr class="header"><th>Topic内部分区</th><th>数据日志</th></tr></thead><tbody><tr class="odd"><td>Partition 0</td><td>1 | 2 | 3 | 4 | 5 | 6 | 7 |</td></tr><tr class="even"><td>Partition 1</td><td>1 | 2 | 3 | 4 | 5 |</td></tr><tr class="odd"><td>Partition 2</td><td>1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |</td></tr></tbody></table><p>消息每次发到对应分区后在分区的最后追加写入，所以分区Partition是一个有序的消息对序列，这些消息在物理上按顺序添加到一个叫做<code>commit log</code>的日志文件中。每个partition中的消息都有一个唯一的编号，称之为<code>offset</code>，用来唯一标识某个分区中的message。</p><p>每个partiton都对应一个commit log文件。一个partition中的message的offset都是唯一的，但是不同的partition中的message的offset可能是相同的，如上面的表格所示。</p><p>kafka一般不会删除消息，不管这些消息有没有被消费，这样不会有消费后删除消息导致的磁盘随机读取，只会根据配置的日志保留时间(<code>log.retention.hours</code>)确认消息多久被删除，而因为消息是连续存储的，等到删除的时候根据时间序列找到需要删除的第一条消息再向后遍历即可做到快速删除，默认kafka保存最近一周的日志消息。kafka的性能与保留的日志数据量大小关系不大，因为一般从队尾消费只需要从最新的offset读取数据，而从某个offset开始消费需要的也仅仅是根据日志索引找到某一个offset的位置之后向后遍历即可，因此保存大量的数据消息日志不会有什么影响。</p><p>每个consumer是基于自己在commit log中的消费offset进行工作的，消费的offset由consumer自己来维护。所以消费者可以通过指定offset来重复消费某些消息或者跳过某些消息。也因此，kafka集群中comsumer的数量对集群的影响并不大。</p><h2 id="副本">副本</h2><p>为了保证可用性，创建一个或多个副本来备份分区数据。我们以一个3个broker的集群来看看消息在分区+备份存储下的情况。</p><p>我们在之前搭建好的集群中创建一个4个分区2个副本的topic：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka1-logs]<span class="comment"># kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 2 --partitions 4 --topic test-multi-1</span></span><br><span class="line">Created topic test-multi-1.</span><br></pre></td></tr></table></figure><p>并查看这个topic的情况：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka1-logs]<span class="comment"># kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic test-multi-1</span></span><br><span class="line">Topic: test-multi-1     TopicId: MSzmgHCqQwef_SaRWPCbKw PartitionCount: 4       ReplicationFactor: 2    Configs:</span><br><span class="line">        Topic: test-multi-1     Partition: 0    Leader: 1       Replicas: 1,0   Isr: 1,0</span><br><span class="line">        Topic: test-multi-1     Partition: 1    Leader: 0       Replicas: 0,2   Isr: 0,2</span><br><span class="line">        Topic: test-multi-1     Partition: 2    Leader: 2       Replicas: 2,1   Isr: 2,1</span><br><span class="line">        Topic: test-multi-1     Partition: 3    Leader: 1       Replicas: 1,2   Isr: 1,2</span><br></pre></td></tr></table></figure><p>可以看到，我们创建了4个分区：</p><p>第一个分区（partition0）：两个副本在broker0和broker1上，其中Leader为broker1。</p><p>第二个分区（partition1）：两个副本在broker0和broker2上，其中Leader为broker0。</p><p>第三个分区（partition2）：两个副本在broker1和broker2上，其中Leader为broker2。</p><p>第四个分区（partition3）：两个副本在broker1和broker2上，其中Leader为broker1。</p><p>Leader节点负责处理这个分区的所有读写请求，Replicas副本会备份Leader的数据。Isr表示在副本中当前存活并且已经同步备份了的副本节点。</p><p>我们可以进去某一个服务器的kafka的日志目录下验证一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 192.168.56.100</span></span><br><span class="line">[root@localhost kafka1-logs]<span class="comment"># cd /usr/local/data/kafka1-logs/</span></span><br><span class="line">[root@localhost kafka1-logs]<span class="comment"># ls</span></span><br><span class="line">cleaner-offset-checkpoint  __consumer_offsets-15  __consumer_offsets-22  __consumer_offsets-3   __consumer_offsets-37  __consumer_offsets-44  __consumer_offsets-7              test2-0</span><br><span class="line">__consumer_offsets-0       __consumer_offsets-16  __consumer_offsets-23  __consumer_offsets-30  __consumer_offsets-38  __consumer_offsets-45  __consumer_offsets-8              test-multi-1-0</span><br><span class="line">__consumer_offsets-1       __consumer_offsets-17  __consumer_offsets-24  __consumer_offsets-31  __consumer_offsets-39  __consumer_offsets-46  __consumer_offsets-9              test-multi-1-1</span><br><span class="line">__consumer_offsets-10      __consumer_offsets-18  __consumer_offsets-25  __consumer_offsets-32  __consumer_offsets-4   __consumer_offsets-47  log-start-offset-checkpoint</span><br><span class="line">__consumer_offsets-11      __consumer_offsets-19  __consumer_offsets-26  __consumer_offsets-33  __consumer_offsets-40  __consumer_offsets-48  meta.properties</span><br><span class="line">__consumer_offsets-12      __consumer_offsets-2   __consumer_offsets-27  __consumer_offsets-34  __consumer_offsets-41  __consumer_offsets-49  recovery-point-offset-checkpoint</span><br><span class="line">__consumer_offsets-13      __consumer_offsets-20  __consumer_offsets-28  __consumer_offsets-35  __consumer_offsets-42  __consumer_offsets-5   replication-offset-checkpoint</span><br><span class="line">__consumer_offsets-14      __consumer_offsets-21  __consumer_offsets-29  __consumer_offsets-36  __consumer_offsets-43  __consumer_offsets-6   test-0</span><br></pre></td></tr></table></figure><p>在56.100这台服务器上，也就是我们的broker0，应该只有分区0和分区1的数据。可以从日志文件中看到，文件夹下topic为test-multi-1的只有<code>test-multi-1-0</code>和<code>test-multi-1-1</code>两个文件夹，这就是分区0和分区1的数据。同理，在56.101服务器上，也就是我们的broker1，只有<code>test-multi-1-0</code>和<code>test-multi-1-2</code>两个文件夹。</p><p>进到<code>test-multi-1-0</code>目录下，可以看到多个日志文件，其中<code>.log</code>文件为消息日志文件，<code>.index</code>文件为基于offset的索引文件，<code>.timeindex</code>是基于时间的索引文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka1-logs]<span class="comment"># cd test-multi-1-0/</span></span><br><span class="line">[root@localhost test-multi-1-0]<span class="comment"># ls</span></span><br><span class="line">00000000000000000000.index  00000000000000000000.<span class="built_in">log</span>  00000000000000000000.timeindex  leader-epoch-checkpoint  partition.metadata</span><br></pre></td></tr></table></figure><h2 id="小结">小结</h2><p>可以这么来理解Topic，Partition和Broker：</p><p>1、一个topic，代表逻辑上的一个业务数据集，比如按数据库里不同表的数据操作消息区分放入不同topic，订单相关操作消息放入订单topic，用户相关操作消息放入用户topic。</p><p>2、对于大型网站来说，后端数据都是海量的，订单消息很可能是非常巨量的，比如有几百个G甚至达到TB级别，如果把这么多数据都放在一台机器上可定会有容量限制问题，那么就可以在topic内部划分多个partition来分片存储数据，不同的partition可以位于不同的机器上，每台机器上都运行一个Kafka的进程Broker。每个partition还可以设置一个Leader和若干个Follower进行备份，partition的个数称为备份因子。</p><p>3、每一个partition可以理解为一个独立的队列，kafka可以使用一些机制保证这一组业务（topic）的各队列（partition）的消费平衡。</p><p>所以对Topic下数据进行分区存储的优点有以下两个： 1、commit log文件会受到所在机器的文件系统大小的限制，分区之后可以将不同的分区放在不同的机器上，相当于对数据做了分布式存储，理论上一个topic可以处理任意数量的数据。 2、为了提高并行度。</p><h1 id="集群容灾">集群容灾</h1><p>在上面创建的3个broker的集群中，我们通过zookeeper确认3个节点是否启动成功，注意，需要在3个节点的服务器上开启对应端口，包括kafka端口和zookeeper端口。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 15] <span class="built_in">ls</span> /brokers/ids</span><br><span class="line">[0, 1, 2]</span><br></pre></td></tr></table></figure><p>我们创建一个新的topic，副本数设置为3，分区数设置为2，并查看topic的情况：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 3 --partitions 2 --topic test-multi-1</span></span><br><span class="line">Created topic test-multi-1.</span><br><span class="line">[root@localhost ~]<span class="comment"># kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic test-multi-1</span></span><br><span class="line">Topic: test-multi-1     TopicId: uHfcZjY4T-SaBfR_ezgsXA PartitionCount: 2       ReplicationFactor: 3    Configs:</span><br><span class="line">Topic: test-multi-1     Partition: 0    Leader: 2       Replicas: 2,1,0 Isr: 2,1,0</span><br><span class="line">Topic: test-multi-1     Partition: 1    Leader: 1       Replicas: 1,0,2 Isr: 1,0,2</span><br></pre></td></tr></table></figure><p>其中第一行是所有分区的概要信息，之后的每一行表示每一个partition的信息。</p><p>Leader节点负责给定partition的所有读写请求，同一个主题不同分区leader副本一般不一样（为了容灾）。</p><p>Replicas表示某个partition在哪几个broker上存在备份。不管这个几点是不是”leader“，甚至这个节点挂了，也会列出。</p><p>Isr 是Replicas的一个子集，它只列出当前还存活着的，并且已同步备份了该partition的节点。</p><p>此时我们向这个Topic发送几条消息试一下，此时broker-list可以加上kafka集群中所有的节点：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># kafka-console-producer.sh --broker-list 192.168.56.100:9092,192.168.56.101:9092,192.168.56.102:9092 --topic test-multi-1</span></span><br><span class="line">&gt;msg1</span><br><span class="line">&gt;msg2</span><br></pre></td></tr></table></figure><p>再启动一个消费者去消费这个topic的消息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># kafka-console-consumer.sh --bootstrap-server 192.168.56.100:9092,192.168.56.101:9092,192.168.56.102:9092 --topic test-multi-1 --from-beginning</span></span><br><span class="line">msg1</span><br><span class="line">msg2</span><br></pre></td></tr></table></figure><p>由于分区0的Leader是2，我们关闭broker.id为2的节点，然后再查看topic信息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Topic: test-multi-1     TopicId: uHfcZjY4T-SaBfR_ezgsXA PartitionCount: 2       ReplicationFactor: 3    Configs:</span><br><span class="line">        Topic: test-multi-1     Partition: 0    Leader: 1       Replicas: 2,1,0 Isr: 1,0</span><br><span class="line">        Topic: test-multi-1     Partition: 1    Leader: 1       Replicas: 1,0,2 Isr: 1,0</span><br></pre></td></tr></table></figure><p>可以看到分区0的Leader已经自动变成了节点1，并且此时Isr中也没有了节点2，所以Leader的选举也是从Isr中选举出来的。</p><p>继续关闭broker.id为1的节点，然后查看topic信息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic test-multi-1</span></span><br><span class="line">Topic: test-multi-1     TopicId: uHfcZjY4T-SaBfR_ezgsXA PartitionCount: 2       ReplicationFactor: 3    Configs:</span><br><span class="line">        Topic: test-multi-1     Partition: 0    Leader: 0       Replicas: 2,1,0 Isr: 0</span><br><span class="line">        Topic: test-multi-1     Partition: 1    Leader: 0       Replicas: 1,0,2 Isr: 0</span><br></pre></td></tr></table></figure><p>此时，就只剩下broker.id为0的一个节点正在正常运行了。</p><p>继续执行发送消息，消费者能够正常消费到消息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># kafka-console-consumer.sh --bootstrap-server 192.168.56.100:9092,192.168.56.101:9092,192.168.56.102:9092 --topic test-multi-1 --from-beginning</span></span><br><span class="line">msg1</span><br><span class="line">msg2</span><br><span class="line">msg3 <span class="comment">#新发送的消息</span></span><br></pre></td></tr></table></figure><p>由此可见，log的partitions分布在kafka集群中不同的broker上，每个broker可以请求备份其他broker上partition上的数据。kafka 集群支持配置一个partition备份的数量。 针对每个partition，都有一个broker起到“leader”的作用，0个或多个其他的broker作为“follwers”的作用。 leader处理所有的针对这个partition的读写请求，而followers被动复制leader的结果，不提供读写（主要是为了保证多 副本数据与消费的一致性）。如果这个leader失效了，其中的一个follower将会自动的变成新的leader。</p><h1 id="集群的生产与消费">集群的生产与消费</h1><h2 id="生产者">生产者</h2><p>生产者将消息发送到topic中去，同时负责选择将message发送到topic的哪一个partition中。通过round-robin做简单的负载均衡，也可以根据消息中的某一个关键字来进行区分。通常第二种方式使用的更多。</p><h2 id="消费者">消费者</h2><p>传统的消息队列传递模式有两种：队列（queue）和发布-订阅（publish-subscribe）。</p><ul><li>queue模式：多个consumer从服务器中读取数据，消息只会到达一个consumer。</li><li>pub-sub模式：消息会被广播给所有的consumer。</li></ul><p>为此Kafka提供了消费组（Consumer Group）的概念。</p><ul><li>queue模式：所有consumer位于同一个consumer group下，同一个consumer group内只会有一个消费者消费到消息。</li><li>pub-sub模式：每个消费者都属于自己唯一的consumer group。</li></ul><p>举例说明，由两个broker组成的kafka集群中的某一个topic拥有4个partition（p0、p1、p2、p3），分别位于不用的broker上，broker0分有p0和p2，broker1分有p1和p3。</p><p>此时一个消费组groupA下有2个消费者A1和A2从这个topic中消费消息，A1被分配到消费p0和p1分区的消息，A2被分配到消费p2和p3分区的消息。</p><p>消费组groupB下有5个消费者B1，B2，B3，B4，B5从这个topic中消费消息，B1-B4分别被分配到消费p0-p3的分区的消息，B5没有分区可以消费。</p><p>此时如果有一条消息发送到p0分区，那么A1和B1都将会消费到这条消息，满足了不同消费组都可以消费到消息，消费组内部仅一个消费者可以消费到消息。</p><p>通常一个topic会有多个消费组去消费，比如系统日志需要被异常收集的系统去统计异常，同时也要被用户活动记录分析的系统去统计用户画像，每一个消费组都是逻辑上的一个订阅者（Logical subscribe）。每个消费组里面由多个消费者组成，提供可扩展和容灾的保证。</p><h2 id="消费顺序">消费顺序</h2><p>要保证消费顺序，需要保证一个partition同一时刻在一个consumer group中只能有一个consumer在消费，并且即使这样，在高并发环境下依然无法保证顺序消费。</p><p>consumer group中的consumer数量不能比partition数量多，否则多出来的消费者消费不到消息。</p><p>Kafka并不能保证同一个topic内多个partition总的消费顺序是一致的，只能保证一个partition内部是顺序，所以保证总体上的顺序消费，只能把partition数量设置为1，同时由于partition数量的限制，consumer数量也只能是1。即使是这样，由于consumer在消费时会有多个线程去获取数据，依然无法保证在高并发情况下的顺序消费。就算非高并发下能满足需求，但是影响性能，浪费了Kafka为了高并发的设计，所以用Kafka实现顺序消费比较少见。</p></div><footer class="post-footer"><div><div style="text-align:center;color:#ccc;font-size:14px">-------------　　　　本文结束　<i class="fa fa-flag"></i>　感谢阅读　　　　-------------</div></div><div class="reward-container"><div>请我一杯咖啡吧！</div> <button> 打赏</button><div class="post-reward"><div> <img src="https://myblog-1303447677.file.myqcloud.com/BlogFrame/wechatpay.png" alt=" 微信支付"> <span>微信支付</span></div><div> <img src="https://myblog-1303447677.file.myqcloud.com/BlogFrame/alipay.png" alt=" 支付宝"> <span>支付宝</span></div></div></div><div class="post-copyright"><ul><li class="post-copyright-author"></li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://zm6666.top/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6Distribute-framework/How-to-use-Kafka-1-InstallAndIntroduction-NativeUse/" title="Kafka使用指南1——简介和安装、原生命令行的使用">https://zm6666.top/分布式框架Distribute-framework/How-to-use-Kafka-1-InstallAndIntroduction-NativeUse/</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="post-tags"><a href="/tags/Java/" rel="tag"><i class="fa fa-tag"></i> Java</a><a href="/tags/Kafka/" rel="tag"><i class="fa fa-tag"></i> Kafka</a></div><div class="post-nav"><div class="post-nav-item"><a href="/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1System-design/ShortUrl/" rel="prev" title="浅谈短链接设计"><i class="fa fa-angle-left"></i> 浅谈短链接设计</a></div><div class="post-nav-item"> <a href="/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6Distribute-framework/How-to-use-Kafka-3-Cluster/" rel="next" title="Kafka使用指南3——Kafka集群架构设计">Kafka使用指南3——Kafka集群架构设计<i class="fa fa-angle-right"></i></a></div></div></footer></article></div><div class="comments utterances-container"></div></div></main><footer class="footer"><div class="footer-inner"><div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">苏ICP备2022038238号-1</a></div><div class="copyright"> &copy; 2019 – <span itemprop="copyrightYear">2024</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">zm</span></div><div class="busuanzi-count"><span class="post-meta-item" id="busuanzi_container_site_uv"><span class="post-meta-item-icon"><i class="fa fa-user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span><span class="post-meta-item" id="busuanzi_container_site_pv"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div><div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动</div><script>var titleTime,OriginTitle=document.title;document.addEventListener("visibilitychange",function(){document.hidden?(document.title="来啊快活啊~"+OriginTitle,clearTimeout(titleTime)):(document.title="咚咚咚"+OriginTitle,titleTime=setTimeout(function(){document.title=OriginTitle},2e3))})</script></div></footer><div class="back-to-top" role="button" aria-label="返回顶部"><i class="fa fa-arrow-up fa-lg"></i> <span>0%</span></div><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script src="https://cdn.jsdmirror.com/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="https://cdn.jsdmirror.com/npm/pangu@4.0.7/dist/browser/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script><script src="https://cdn.jsdmirror.com/npm/hexo-theme-next@8.18.2/source/js/comments.min.js"></script><script src="https://cdn.jsdmirror.com/npm/hexo-theme-next@8.18.2/source/js/utils.min.js"></script><script src="https://cdn.jsdmirror.com/npm/hexo-theme-next@8.18.2/source/js/motion.min.js"></script><script src="https://cdn.jsdmirror.com/npm/hexo-theme-next@8.18.2/source/js/next-boot.min.js"></script><script src="https://cdn.jsdmirror.com/npm/hexo-generator-searchdb@1.4.1/dist/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script><script src="https://cdn.jsdmirror.com/npm/hexo-theme-next@8.18.2/source/js/third-party/search/local-search.min.js"></script><script src="https://cdn.jsdmirror.com/npm/hexo-theme-next@8.18.2/source/js/third-party/pace.min.js"></script><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script class="next-config" data-name="leancloud_visitors" type="application/json">{"enable":true,"app_id":"WYpTHDdtwSPYrGnPn3Dd6VK8-gzGzoHsz","app_key":"167XRDBA8P2enbdqnG3050K1","server_url":"https://wypthddt.lc-cn-n1-shared.com","security":true,"betterPerformance":true}</script><script src="https://cdn.jsdmirror.com/npm/hexo-theme-next@8.18.2/source/js/third-party/statistics/lean-analytics.min.js"></script><script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdmirror.com/npm/mathjax@3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script><script src="https://cdn.jsdmirror.com/npm/hexo-theme-next@8.18.2/source/js/third-party/math/mathjax.min.js"></script><script src="https://cdn.jsdmirror.com/npm/quicklink@2.3.0/dist/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script><script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://zm6666.top/%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%86%E6%9E%B6Distribute-framework/How-to-use-Kafka-1-InstallAndIntroduction-NativeUse/"}</script><script src="https://cdn.jsdmirror.com/npm/hexo-theme-next@8.18.2/source/js/third-party/quicklink.min.js"></script><script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"zhaomin6666/BlogUtterances","issue_term":"title","theme":"github-light"}</script><script src="https://cdn.jsdmirror.com/npm/hexo-theme-next@8.18.2/source/js/third-party/comments/utterances.min.js"></script></body></html>